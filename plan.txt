一、项目定位与核心目标

1.1 问题背景

在图像分类任务中，训练集往往被当成“既定事实”：只要丢给模型训练即可。但现实中，数据集普遍存在这些问题：

含有噪声标注、低质量样本；

类内冗余严重，大量“长得差不多”的样本反复出现；

决策边界附近的关键样本比例不足；

难以评估后续新采集数据的价值。

传统数据选择／数据裁剪方法（如基于 loss、EL2N、GraNd、Forgetting、MoSo 等）有两个共性缺陷：

主要针对“已有训练集”，难以直接对未见样本打分；

强烈依赖特定训练过程和模型结构，缺乏可复用、可解释的“样本质量模型”。

plan

1.2 本项目的目标

本项目要做的不是简单的“再造一个数据选择算法”，而是设计一个面向图像分类任务的样本质量评估框架，具有以下能力：

(1) 给每个样本一个可解释的质量得分，明确区分“好样本”“一般样本”“坏样本”：

得分越高，表示语义更干净；

在类空间中覆盖更充分；

在类内关键变化方向上更有价值。

(2) 这个得分不仅能作用于当前训练集，还能对训练阶段未见的新样本进行快速评分：

新采集的数据不必重新训练就能知道“值不值得加入训练集”。

(3) 得分可以自然用于数据选择／数据裁剪：

例如指定只保留 top 50% 的高质量样本；

或在样本总量固定的约束下，用 Selection Optimization 选出最优子集。

(4) 权重学习：

静态指标本身是 train-free 的（基于 CLIP 特征和类内结构），但各指标的重要性会随数据集、任务而变化；

我们使用一次代理模型训练动态（earlyloss、coverage、stability）来学习这些静态指标的权重，得到一个“数据驱动”的评分模型；

训练动态只参与“教学”，不直接参与最终评分，保证最终评分函数能泛化到未见样本。

(5) 在静态指标之前引入轻量的 Dataset Adapter，对 CLIP 图像特征做数据集级的适配，使得静态指标在当前数据集上更稳定、更合理，同时不破坏对未见样本的泛化能力。

二、整体框架概览

从流程视角，整个框架可以分为四个阶段：

(0) 特征抽取与 Dataset Adapter 训练：

使用预训练 CLIP 的图像编码器和文本编码器；

冻结 CLIP 主体参数，训练一个轻量 Dataset Adapter，使图像特征在当前数据集上与类别语义更加对齐；

得到适配后的图像特征 g_i 作为静态指标的统一特征空间。

(1) 静态多指标评分（Static Scoring）：

基于 adapter 后的特征 g_i，构造三个 train-free 静态指标：

SA：语义对齐度（Semantic Alignment）；

Div：类内多样性覆盖度（基于同类 kNN 距离均值的稀疏度）；

DDS：类内难度方向得分（基于 PCA 的低方差方向投影）。

(2) 从训练动态学习权重（Weight Learning via Dynamics）：

在原始图像上以 K 折交叉验证训练一个代理分类模型（如 ResNet-18），按折记录训练子集与验证子集（OOF）的 logits 轨迹；

基于训练轨迹构造训练视角分量 A/B/C/R，刻画“吸收效率、边界推进信息、覆盖互补增益、极端噪声风险”；

基于 OOF 验证轨迹构造验证视角分量 T/V，分别刻画“可迁移增益”和“后期持久难度”；

将 A/B/C/T/V/R 融合并归一化得到动态效用标签 u_i；

用带 L2 正则的线性回归（Ridge），将 u_i 回归到 (SA, Div, DDS)，学习出静态指标的权重 w。

(3)  基于最终得分进行数据选择与 Selection Optimization：

最终评分定义为 Score(x) = Σ_k ẇ_k · feature_k，其中 ẇ 由 w 归一化而来；

直接用 Score 排序可以做简单数据选择；

进一步，在 Selection Optimization 中引入可学习的选择变量 d_i，在给定选样比例约束下，优化“整体被选子集的总 Score”。

整体实现了：

train-free 静态评分（可泛化到未见样本）；

利用一次训练动态学习权重（提高评分模型与任务的一致性）；

支持静态排序选择和基于优化的 Selection Optimization；

在静态指标前加入 Dataset Adapter，提升 CLIP 特征在目标数据集上的适配性。

三、Dataset Adapter 模块设计

3.1 设计目标

引入 Dataset Adapter 的目的：

适配预训练 CLIP 在目标数据集（如 CIFAR-10/100、Tiny-ImageNet）上的分布偏移，使类内结构与类间语义更清晰；
提升 SA、Div、DDS 这些静态指标在当前数据集上的表达质量；
仅在特征层做轻量变换，不改变 CLIP 主干参数；
不破坏“静态指标 → 动态监督 → 权重学习 → 静态评分函数”的整体逻辑；
对未见样本依然可直接前向计算 adapter 并评分。

与仅适配图像侧相比，同时引入图像端与文本端 adapter 的优势在于：类别语义原型本身也会受到提示词形式与域偏移的影响；在冻结 CLIP 的前提下，让两端都通过小参数模块吸收“数据集特有知识”，可以更稳定地改善图文对齐质量，从而为后续的 margin-式 SA 与结构性指标（Div / DDS）提供更可靠的共同嵌入空间。

3.2 结构形式（双端、维度保持的轻量 MLP）

设 E_I(·) 为冻结的 CLIP 图像编码器，E_T(·) 为冻结的 CLIP 文本编码器。对第 i 个图像样本 I_i：

f_i = E_I(I_i) ∈ ℝ^d,     f_i ← L2Norm(f_i)

对类别 c 的文本提示词 T_c（prompt）：

T_c = "A photo of [CLS]"，其中 [CLS] 用类别名称替换；
u_c = E_T(T_c) ∈ ℝ^d,     u_c ← L2Norm(u_c)

为进行数据集层面的适配，我们为两种模态分别引入“维度保持（dimension-preserving）”的 adapter：

图像端 adapter：
g_i = A_I(f_i) = W_2^I · σ(W_1^I f_i + b_1^I) + b_2^I,     g_i ← L2Norm(g_i)

文本端 adapter：
t̃_c = A_T(u_c) = W_2^T · σ(W_1^T u_c + b_1^T) + b_2^T,     t̃_c ← L2Norm(t̃_c)

其中：

W_1^I ∈ ℝ^{h×d}, W_2^I ∈ ℝ^{d×h},   W_1^T ∈ ℝ^{h×d}, W_2^T ∈ ℝ^{d×h}；
h 为瓶颈维度（如 256），σ 为非线性激活函数（ReLU 或 GELU）；
两端输出都保持 d 维，且均进行 L2 归一化以保持几何稳定性与可比性。

该设计具有：

参数量远小于 CLIP 主体，仅做“轻量迁移”而非重训练；
同时修正图像分布偏移与文本原型偏移，提升图文对齐的一致性；
适配后的共同空间更利于 PCA / kNN 等结构性操作（Div / DDS）。

3.3 训练目标与流程（冻结 CLIP，仅训练双端 adapter）

训练目标采用对比学习式的语义对齐损失，使同一图像与其对应类别文本在适配后空间中更接近，并与其他类别文本拉开距离。对样本 (I_i, y_i)，定义相似度：

s_{i,c} = cos(g_i, t̃_c) / τ

其中 cos(·,·) 为余弦相似度，τ 为温度系数（默认 0.07）。

损失函数（InfoNCE / softmax-contrastive）：

L_adapter(i) = - log ( exp(s_{i,y_i}) / Σ_{c=1}^C exp(s_{i,c}) )

总体损失为 batch 内平均：L_adapter = (1/B) Σ_i L_adapter(i)。

训练细节与默认参数（移植并固化为本项目默认设置）：

优化器：Adam；
初始学习率：1e-4；
训练轮数：30 epochs；
学习率调度：StepLR(step_size=30, gamma=0.1)；
batch size（随数据集）：CIFAR-10/100 为 256，Tiny-ImageNet 为 64，ImageNet-1k 为 512；
温度系数：τ=0.07（可作为可调超参数，但默认固定以保证不同实验的可比性）。

训练过程：

(1) 冻结 CLIP 的所有参数，仅训练 A_I 与 A_T 的参数（W_1^I, W_2^I, b_1^I, b_2^I, 以及 W_1^T, W_2^T, b_1^T, b_2^T）；
(2) 在完整训练集上，按 batch 前向计算 f_i → g_i，并对所有类别计算 u_c → t̃_c，基于上述损失更新双端 adapter；
(3) 训练完成后固定 A_I 与 A_T，后续所有静态指标与评分计算都基于 (g_i, t̃_c)，不再更新 adapter。

3.4 与后续模块的关系

顺序关系：

先训练双端 Adapter（A_I, A_T）并固定；
再基于适配后的共同空间计算 SA、Div、DDS；
再在原始图像上以 K 折交叉验证训练代理模型并记录训练动态（该动态构造不依赖 adapter）；
最后用动态构造 u_i，并用 (SA, Div, DDS) 回归 u_i 学习静态权重 ẇ。

因此不存在“动态影响 adapter，再用动态监督静态指标”的循环依赖，逻辑清晰稳定。

对未见样本：

对新样本 x_new，先用 CLIP 提取 f_new，再经图像端 adapter 得到 g_new；
并使用固定的类别文本原型 t̃_c（由 prompt → E_T → A_T 得到）；
再基于 (g_new, t̃_c) 计算 SA_new / Div_new / DDS_new；
最后用固定 ẇ 得到 Score(x_new)。


四、静态多指标样本评分模块（基于 adapter 后特征）

这一部分完全不依赖代理模型训练动态，是支撑“未见样本评分”的关键；也是后续动态权重学习的输入特征来源。

记：

训练样本 (x_i, y_i)；

CLIP 图像编码器输出 f_i，图像端 Adapter 输出 g_i（已 L2 归一化）；
CLIP 文本编码器对类别提示词输出 u_c，文本端 Adapter 输出适配后的类别原型 t̃_c（已 L2 归一化）。

所有静态指标均在 g_i 所在的特征空间中构建。

4.1 语义对齐度（Semantic Alignment, SA）

语义对齐度（Semantic Alignment, SA）用于度量样本图像内容与其标注类别语义之间的一致性。直观地说，如果一张图像确实属于类别 y_i，那么它在高维语义空间中应当更接近“该类别的语义描述”，而远离其他类别的语义描述。本项目基于冻结的 CLIP 图像编码器和文本编码器，在此基础上引入 Dataset Adapter，对图像侧特征进行数据集层面的轻量适配，并在适配后的特征空间中定义 SA 作为样本质量的一个核心指标。

本节首先给出基于余弦相似度的原始 SA 定义，然后在此基础上引入 margin 形式的改进版 SA，解释其设计动机、数学形式及实现方案。

（1）特征表示与基础设定

设 E_I(·) 为冻结的 CLIP 图像编码器，E_T(·) 为冻结的 CLIP 文本编码器。为适配目标数据集分布，我们在图像侧与文本侧同时引入 Dataset Adapter（A_I, A_T），得到适配后的多模态表示：

g_i = A_I(E_I(I_i)),

其中 I_i 为第 i 个图像样本，g_i ∈ R^d 为该样本在适配后语义空间中的图像表示。若未启用图像端 Adapter，则有 g_i = E_I(I_i)。

对于类别 c，对其构造文本描述 prompt，例如：

T_c = "A photo of [CLS]"（用类别名称替换 [CLS]），

先通过文本编码器获得基础语义嵌入：

u_c = E_T(T_c),

再经文本端 Adapter 得到适配后的类别语义原型：

t̃_c = A_T(u_c).

其中 u_c, t̃_c ∈ R^d。经过 L2 归一化处理后，g_i 与 t̃_c 位于同一语义空间，可以使用余弦相似度刻画图像与类别语义之间的关系。

（2）原始 SA 定义：正类语义相似度（Cosine-based SA）

在最基础的设计中，语义对齐度 SA_i 定义为样本图像与其标注类别文本特征之间的余弦相似度：

SA_i^(cos) = cos(g_i, t̃_{y_i}),

其中 y_i 为样本 i 的标注类别。该定义反映了样本在语义空间中与“正确类别”之间的接近程度，具有以下特征：

1）形式简单、可解释性强：
SA_i^(cos) 越大，说明图像在语义空间上越接近其标注类别的文本描述，直观表示“图像语义与标签是否匹配”。

2）实现方便：
在实际实现中，只需对 g_i 和 t̃_{y_i} 做 L2 归一化，然后做一次点积即可得到 SA_i^(cos)。

然而，SA_i^(cos) 仅关注“图像与正类的相似度”，并未显式考虑“图像与其他类别的区分度”。在实际分类任务中，如果一个样本同时与多个类别都具有较高相似度，那么即使它对正类相似度较高，这个样本仍然是“语义模糊”或“容易混淆”的样本，属于质量可疑的样本类型。为增强 SA 对这种情况的敏感度，本项目在上述基础上进一步引入 margin 形式的语义对齐度。

（3）改进的 margin 语义对齐度（Margin-based SA）

为了同时刻画“对正类的贴合程度”和“与其他类别的区分程度”，本项目将 SA 定义为正类相似度与最相似负类相似度之间的差值，即 margin：

SA_i = cos(g_i, t̃_{y_i}) − max_{c ≠ y_i} cos(g_i, t̃_c).

其中：

1）cos(g_i, t̃_{y_i})：
表示样本在语义空间中与标注类别语义的贴合程度，越大越好。

2）max_{c ≠ y_i} cos(g_i, t̃_c)：
表示样本在“所有非标注类别”中，与其最相似的那个负类的语义相似度。如果这个值很高，说明该样本对其他类别也容易产生混淆。

因此，SA_i 的含义可以解释为：

SA_i 大：样本不仅与正类高度对齐，而且与所有负类保持足够间隔，语义清晰、标签可靠、视觉信息明确；

SA_i 小甚至为负：样本与正类的相似度有限，或与某个负类几乎一样接近，说明样本存在语义模糊、标注有问题、信息不足或噪声较重等情况。

与原始的 SA_i^(cos) 相比，margin 形式的 SA 具备以下优势：

1）更符合分类任务的判别逻辑：
分类问题的本质不仅是“与正确类别接近”，更是“与正确类别相比，和其他类别拉开足够差距”。margin 形式正是把这种“相对优势”显式量化出来。

2）对噪声样本和模糊样本更加敏感：
噪声样本往往在多个类别上都有较高相似度，此时 cos(g_i, t̃_{y_i}) 可能仍然不低，但 max_{c ≠ y_i} cos(g_i, t̃_c) 也会较高，导致 margin 下降。这样就能有效将“语义模糊样本”标记为低质量样本。

3）与 Adapter 训练目标保持一致：
Adapter 的训练过程本身就是通过对比学习提高正类对齐、削弱负类混淆。用 margin SA 作为质量指标，可以更自然地反映 Adapter 对“语义空间可分性”的改善。

4）可解释性更强：
对于某个样本，既可以查看 cos(g_i, t̃_{y_i}) 看是否“正类相似度不足”，也可以查看 max_{c ≠ y_i} cos(g_i, t̃_c) 看是否是“被某个负类强烈吸引”，从而给出更细粒度的分析。

（4）SA 的数学形式与实现步骤

在具体实现中，考虑一批样本的图像特征和全部类别的文本特征，定义：

G = [g_1; g_2; …; g_N] ∈ R^{N×d},
T = [t_1; t_2; …; t_C] ∈ R^{C×d},

其中每一行是一个 L2 归一化后的特征向量。通过矩阵乘法可一次性得到所有样本在所有类别上的余弦相似度：

S = G T^T ∈ R^{N×C}.

对于第 i 个样本，其标注类别为 y_i，则有：

1）正类相似度：
s_i^{(pos)} = S[i, y_i] = cos(g_i, t̃_{y_i}).

2）最相似负类相似度：
先在第 i 行中屏蔽掉列 y_i，对剩余列求最大值：
s_i^{(neg)} = max_{c ≠ y_i} S[i, c].

3）margin 式语义对齐度：
SA_i = s_i^{(pos)} − s_i^{(neg)}.

此过程可以通过简单而高效的张量操作实现：

使用矩阵乘法得到 S；

通过 gather 操作取出正类相似度；

构造布尔掩码屏蔽正类位置，在其余位置上求行最大值作为负类相似度；

二者相减得到 SA_i。

在代码中，SA 计算函数 _margin_similarity 即实现上述逻辑，支持批量计算并兼容不同设备（CPU/GPU）。

（5）原始 SA 与 margin SA 在项目中的关系

本项目在设计上同时保留“原始 SA（仅正类余弦）”和“margin SA（正类−最相似负类）”两种视角：

1）原始 SA（cosine-based）：
SA_i^(cos) = cos(g_i, t̃_{y_i})
主要用于直观评估“样本与其标签语义的正向契合程度”，在一些分析中可以直接使用这一简单指标，便于解释和展示。

2）margin SA（margin-based）：
SA_i = cos(g_i, t̃_{y_i}) − max_{c ≠ y_i} cos(g_i, t̃_c)
作为本项目实际使用的主版本 SA，用于样本质量评分、数据选择、以及后续与 SDS、DDS 等指标联合分析。它在反映样本“是否容易被其他类别混淆”方面具有更强的能力，更符合样本质量评估任务的需求。

在后续实验与分析中，本项目会以 margin SA 为主，必要时对比展示原始 SA^(cos)，以便分离“正类对齐问题”和“负类混淆问题”。

（6）归一化（更新：类内 0.2% 分位点 min-max 归一化，支持未见样本外推）

由于 SA 将与 Div、DDS 线性加权得到总分 Score，并进一步用于排序选择与未见样本质量评估，因此必须将 SA 映射到统一尺度 [0,1]。与传统的全局 min-max 不同，本项目采用“类内分位点 min-max”作为固定标尺：用训练集每个类别内部的 0.2% 与 99.8% 分位点作为有效范围端点，并对超界样本进行饱和截断，从而兼顾鲁棒性与可外推性。

记 SA 的原始 margin 分值为 SA_raw(i)，样本 i 的类别为 y_i=c。对每个类别 c，在训练集内收集该类所有 SA_raw，计算：

q_low^c = Quantile(SA_raw | y=c, 0.002)
q_high^c = Quantile(SA_raw | y=c, 0.998)

对属于类别 c 的任意样本 i（包括训练集样本与未见样本），定义类内归一化后的 SA 分数为：

SA_i = clip( (SA_raw(i) - q_low^c) / (q_high^c - q_low^c), 0, 1 )

其中 clip(·,0,1) 表示将结果截断到 [0,1] 区间；这意味着：

若 SA_raw(i) ≤ q_low^c，则 SA_i = 0（极低语义对齐样本）；

若 SA_raw(i) ≥ q_high^c，则 SA_i = 1（极高语义对齐样本）；

若 SA_raw(i) 处于 [q_low^c, q_high^c] 内，则线性映射到 (0,1) 区间，保留“幅度差异”。

数值退化处理：若某类出现 q_high^c ≈ q_low^c（该类 SA_raw 几乎为常数），则该类所有样本 SA_i 统一置为 0.5。

该归一化方式的优点在于：
1）尺度对齐：与 Div、DDS 同一 [0,1] 空间，便于线性加权；
2）鲁棒性：不受极端异常值影响（分位点而非 min/max）；
3）可外推：未见样本即使超出训练集范围，也会自然饱和到 0 或 1，不会产生不可控的 >1/<0。

4.2 多样性覆盖度 Div（基于 kNN 距离的 rank-based 稀疏度）

设计动机：

类内空间中越“稀疏”的样本，越可能提供新的变化信息和泛化收益；
我们希望构造一个对特征尺度不敏感、能跨数据集稳定对比的多样性指标；
因此采用“基于 kNN 距离的类内排序”，而非绝对距离阈值。

(1) 特征空间构建

对每个样本使用 adapter 后特征 g_i（已 L2 归一化）；
对每个类别 c，收集该类的特征集合 G_c = { g_i | y_i = c }，样本数为 N_c。

(2) 计算类内 kNN 距离 d_i（更新：由 k-th 距离改为前 k 近均值）

对类别 c 内每个样本 i，记其适配后特征为 g_i。令 KNN_c(i) 表示在同类样本集合 G_c \ {g_i} 中，按欧氏距离从近到远选取的前 k 个最近邻样本索引集合：

KNN_c(i) = { j_1(i), j_2(i), …, j_k(i) }, 且 ||g_i − g_{j_1(i)}||2 ≤ … ≤ ||g_i − g{j_k(i)}||_2.

本项目将类内稀疏度的原始度量定义为“前 k 个最近邻距离的均值”：

d_i = (1/k) · Σ_{m=1..k} || g_i − g_{j_m(i)} ||_2.

直观解释：

在类内密集区域，样本周围的近邻更近，前 k 个距离整体更小 → d_i 小；

在类内稀疏区域，样本需要更远的范围才能找到足够近邻，前 k 个距离整体更大 → d_i 大。

与“第 k 个最近邻的单点距离（k-th distance）”相比，使用前 k 近均值具有更好的稳定性与鲁棒性：
1）对局部噪声更不敏感：单个异常近邻/远邻对均值的影响被平均化；
2）对密度不均更平滑：能更连续地刻画不同密度区域的差异；
3）更适合后续归一化：d_i 的数值分布更稳定，便于用分位点标尺映射到 [0,1]。

参数 k：
k 为全局固定超参数，支持两种语义：正整数表示邻居个数；0~1 小数表示“类别内样本比例”（默认 k=0.05，即每类取 5% 邻居）。实际计算按每个类别样本数分别解析 k 并限制到 [1, n_c-1]，用于控制局部密度估计的平滑程度。

(3) 将 d_i 转为相对稀疏度 rank_i

在类别 c 中，对所有 d_i 升序排序：
d_(1) ≤ d_(2) ≤ ... ≤ d_(N_c)
定义样本 i 的 rank_i 为其在排序中的位置（从 0 到 N_c − 1）；
rank_i 越大，代表样本越处于类内稀疏区域。

(4) 归一化（更新：不使用 rank 等间隔分位数）

为避免 rank 等间隔分位数将“距离幅度信息”抹平，同时保持指标尺度对齐与未见样本可评估性，本项目不再对类内 kNN 距离做排序赋分，而是直接在距离空间上采用类内分位点 min-max 归一化。

对类别 c 内每个样本 i，先得到 Div 的原始距离度量 Div_raw(i)=d_i（本方案中 d_i 为“同类前 k 个最近邻距离的均值”，见下文更新的 d_i 定义）。随后在训练集内对每个类别 c 统计该类所有 Div_raw：

q_low^c = Quantile(Div_raw | y=c, 0.002)
q_high^c = Quantile(Div_raw | y=c, 0.998)

并对属于类别 c 的任意样本 i 定义：

Div_i = clip( (Div_raw(i) - q_low^c) / (q_high^c - q_low^c), 0, 1 )

解释：

Div_i 越大表示样本处于更稀疏的类内区域（更可能提供新变化覆盖）；

分位点归一化抑制极端距离对尺度的破坏，并保留 0.2%~99.8% 区间内的幅度差异；

未见样本若更稀疏（距离超出 q_high^c），会直接得到 Div_i=1；若更密集（距离低于 q_low^c），则 Div_i=0。

数值退化处理与 SA 相同：若 q_high^c ≈ q_low^c，则该类 Div_i 统一置为 0.5。

(5) 未见样本的 Div_new（更新：对应均值距离 + 分位点标尺归一化）

对未见新样本 x_new（其类别为 c_new，若无真实标签可用预测标签代替）：
1）用冻结 CLIP 图像编码器与 Dataset Adapter 得到特征 g_new；
2）在训练阶段保存的该类特征集合 G_{c_new} 中，检索同类前 k 个最近邻集合 KNN_{c_new}(new)，计算原始距离均值：

Div_raw(new) = d_new = (1/k) · Σ_{m=1..k} || g_new − g_{j_m(new)} ||_2.

3）使用训练阶段在类别 c_new 上统计得到的分位点标尺 (q_low^{c_new}, q_high^{c_new})（分别为 0.2% 与 99.8% 分位点），进行类内归一化并截断：

Div_new = clip( (d_new − q_low^{c_new}) / (q_high^{c_new} − q_low^{c_new}), 0, 1 ).

该过程只需一次 kNN 查询与常数级归一化运算，不依赖训练动态信息；同时由于采用分位点标尺与截断，能够在未见样本距离超出训练集范围时仍稳定输出 [0,1] 分数（超出上界饱和为 1，低于下界饱和为 0）。

数值退化处理：若该类出现 q_high^{c_new} ≈ q_low^{c_new}，则 Div_new 置为 0.5，避免除零。

4.3 类内难度方向得分 DDS（Difficulty Direction Score）

目的：捕捉样本在类内“罕见但重要的变化方向”上的偏移，补充 SA（语义）与 Div（位置稀疏度）。

思路：

对每个类别单独在 adapter 后特征空间 G_c 上做 PCA；

类内低方差方向代表“少见但重要”的变化（例如特殊姿态、视角、光照等）；

在这些方向上偏移较大的样本，被视作具有较高“难度方向贡献”。

做法：

(1) 对每个类别 c，取 G_c 中所有特征 g_i，计算类内均值 μ_c。

(2) 对 G_c 做 PCA / 特征分解，得到主方向向量 {u_k} 及对应方差 λ_k，并按 λ_k 从小到大排序。

(3) 将特征值按从小到大排序后，选择“所选方向特征值之和占总特征值之和位于 [eigval_lower_bound, eigval_upper_bound] 区间”的方向集合。具体实现时先跨过下界，再在不超过上界的前提下向上累积选择方向；若下界大于 0 且不存在低于下界的方向，则至少去除一个最小特征值方向。参数 k 不再表示比例，而用于约束最少选择方向数（在不突破上界时尽量满足），以避免仅按上界得到过少方向。为提高数值稳定性，PCA 协方差矩阵可加入小的对角正则项。

(4) 对类别为 c 的样本 i，定义：

DDS_i = Σ_{k ∈ low-variance} |⟨g_i − μ_c, u_k⟩|

性质：

DDS 高：样本在低方差方向上偏移较大，往往是“罕见但有价值的变化”，可能靠近类边界或覆盖少见模式；

DDS 低：样本在这些方向上接近类均值，更像“典型中心样本”。

归一化方案（类内分位点 min-max）：

DDS 的原始分值 DDS_raw(i) 由类内 PCA 的低方差方向投影定义（见前文）。由于不同类别的特征分布与方差结构差异较大，直接全局归一化会引入类间尺度偏置；同时，本项目要求对未见样本具备稳定的质量评估能力，因此 DDS 采用与 SA、Div 一致的“类内分位点 min-max”归一化。

对每个类别 c，在训练集内收集该类所有 DDS_raw，计算：

q_low^c = Quantile(DDS_raw | y=c, 0.002)
q_high^c = Quantile(DDS_raw | y=c, 0.998)

对属于类别 c 的任意样本 i（训练/未见均可）定义：

DDS_i = clip( (DDS_raw(i) - q_low^c) / (q_high^c - q_low^c), 0, 1 )

其中 clip(·,0,1) 表示饱和截断。数值退化处理同上：若 q_high^c ≈ q_low^c，则该类 DDS_i 统一置为 0.5。

该归一化在保证三指标统一尺度的同时，能够减少类间偏置，并使 DDS 在未见样本到来时无需重新统计全局 min/max，即可给出稳定可比的 [0,1] 评分。

***整体静态特征向量：

f_i = [ SA_i, Div_i, DDS_i ]^T

将作为后续动态权重学习的输入。

五、基于训练动态学习评分权重

5.1 问题动机

SA / Div / DDS 三个静态指标“谁更重要”，不同数据集与任务差异很大；

手工设权重（如平均加权）缺乏依据，超参数搜索又很耗时；

代理模型训练动态中包含“哪些样本对训练真正有用”的信息；

但训练动态本身依赖模型与训练过程，不能直接用于未见样本评分。

因此，本项目设计为：

用代理模型训练动态构造样本效用标签 u_i（0–1 的连续值）；

再用静态特征 f_i = (SA_i, Div_i, DDS_i) 回归 u_i；

学得一个可复用的静态评分函数 Score(·)。

训练动态是“老师”，静态指标是“学生”。

5.2 代理模型与记录

代理模型：如 ResNet-18，以 K 折交叉验证方式训练（默认 K=5），每折训练 E 个 epoch。

交叉验证的目标不是为了“更高的代理模型精度”，而是为了在不使用测试集的前提下，引入 OOF（out-of-fold）预测轨迹，使后续动态分量能够显式利用“验证/预测视角”的信息。

设训练集全局索引为 i ∈ {0,...,N-1}。第 f 折包含训练子集 I_train^f 与验证子集 I_val^f，且 I_train^f ∪ I_val^f 为全体样本，I_train^f ∩ I_val^f = ∅。

【按折保存的关键日志（最小必要信息）】
对每一折 f 保存 fold_f.npz（或等价格式），至少包含：

(1) train_indices：I_train^f（全局索引）
(2) val_indices：I_val^f（全局索引）
(3) train_logits：z_train^f[t, j, :] ∈ ℝ^C（训练子集的 logits 轨迹）
(4) val_logits：z_val^f[t, k, :] ∈ ℝ^C（验证子集的 logits 轨迹）

说明：
- 不额外保存 label：可通过 train_indices / val_indices 从原始数据集读取 y_i。
- 不额外保存 correct / loss：可由 logits 与 label 快速计算得到。

【跨折对齐与聚合规则】
- 训练视角分量（A/B/C/R）：样本 i 在 K−1 个折中作为训练样本出现，因此存在 K−1 条训练轨迹；先在每一折内计算该折给出的 A_f(i),B_f(i),C_f(i),R_f(i)，再在折间做鲁棒聚合（默认 median，可选 mean），得到全局 A(i),B(i),C(i),R(i)。
- 迁移耦合分量（TransferGainScore, T）：T 的目标样本同样是“训练子集中的样本”，但其定义显式依赖该折的 OOF 验证改善曲线；因此样本 i 也会在 K−1 个折中得到 {T_f(i)}，需与 A/B/C/R 相同做折间聚合（median/mean）得到 T(i)。
- 验证视角分量（PersistentDifficultyScore, V）：V 的目标样本是“作为验证子集被预测的样本”，样本 i 仅在 1 个折中作为验证样本出现，拥有唯一的 OOF 预测轨迹，因此直接计算 V(i) 并写回全局索引位置，不需要折间聚合。


5.3 AbsorptionEfficiencyScore：吸收效率得分（A）

【定位与目标】
AbsorptionEfficiencyScore 用于刻画“样本是否能在训练早期被模型高效吸收并形成有效梯度信号”。它强调两个要点：
1）早期进展：loss 在早期窗口内下降更快，说明样本可被迅速吸收；
2）难度适中：样本不应在早期呈现极端异常（过难/异常噪声导致 loss 过高或学习轨迹异常），否则容易“伤及无辜”。

A 的设计目标是：鼓励“进展快 + 难度适中”的样本，同时对极端异常样本保持克制的奖励。

【输入与记录】
来自代理模型训练日志（.npz）：

每轮 loss：ℓ_t(i)，t=1..E

标签：y_i
（可选 indices 用于与其他分量对齐）

【计算步骤与数学形式】
（1）早期窗口
设早期窗口长度为 E_e（默认取总轮数的 20%，且至少 5 轮）：
t ∈ T_e = {1,2,…,E_e}

（2）对 loss 做 log 压缩以减少长尾
\tildeℓ_t(i) = log(1 + ℓ_t(i))

（3）构造“早期难度水平”和“早期进展”
Level(i) = mean_{t∈T_e} \tildeℓ_t(i)
Progress(i) = \tildeℓ_{t=1}(i) − \tildeℓ_{t=E_e}(i)

其中 Progress 越大，表示早期下降越明显。

（4）类内稳健标准化（避免类别尺度偏置）
对每个类别 c，计算类内 robust z：
z_L(i) = robust_z( Level(i) | y=c )
z_P(i) = robust_z( Progress(i) | y=c )

（5）将“进展快”映射为奖励项，将“难度适中”映射为保守门控项
Speed(i) = σ( z_P(i) )
Moderate(i) = exp( − 0.5 * z_L(i)^2 )

（6）原始分数与归一化
A_raw(i) = Speed(i) * Moderate(i)
随后做类内分位点 min-max 归一化到 [0,1]：
A(i) = clip( (A_raw(i) − q_low^c) / (q_high^c − q_low^c), 0, 1 )

其中 q_low^c/q_high^c 是 A_raw 在类 c 内的分位点（默认 0.2%/99.8%）。

【超参数含义】

E_e：早期窗口比例与最小轮数（控制“早期”的时间尺度）

q_low, q_high：分位点归一化的鲁棒性（抑制离群点挤压分布）

5.4 InformativenessScore：信息增益得分（B）

【定位与目标】
InformativenessScore 用于刻画“样本是否在训练过程中提供了有信息量的决策边界推进”。它的核心思想是：

仅“难”不够：需要难但可被推进；

仅“进展”不够：需要发生在具有区分意义的位置（靠近边界/存在混淆）。

因此 B 同时度量：
1）Hardness：样本在后期是否仍处于边界附近（仍有区分压力）；
2）Improve：样本从早期到后期的 margin/gap 是否显著改善（说明其促进了边界推进，而非纯噪声）。

【输入与记录】
来自代理模型训练日志（.npz）：

每轮 logits：z_t(i) ∈ R^C

标签：y_i

【计算步骤与数学形式】
（1）由 logits 得到 softmax 概率
p_t(k|i) = softmax(z_t(i))_k

（2）定义“类间 gap”
令真实类概率 p_true(t,i)=p_t(y_i|i)
令最大非真实类概率 p_other(t,i)=max_{k≠y_i} p_t(k|i)
gap(t,i) = p_true(t,i) − p_other(t,i)

gap 越小，表示越靠近决策边界（甚至被错分为负值区域）。

（3）Hardness：后期边界附近程度（软门控）
设阈值 τ_g 与平滑尺度 s_g：
α(t,i) = σ( (τ_g − gap(t,i)) / s_g )

gap < τ_g 时 α 更大（更“靠边界/更难”）。
取后期窗口 T_l（默认末尾 20%，至少 5 轮）：
Hardness(i) = mean_{t∈T_l} α(t,i)

（4）Improve：从早期到后期的 gap 改善程度
设早期窗口 T_e、后期窗口 T_l：
Δgap(i) = mean_{t∈T_l} gap(t,i) − mean_{t∈T_e} gap(t,i)
Improve(i) = σ( Δgap(i) / τ_Δ )

（5）原始分数与归一化
B_raw(i) = Hardness(i) * Improve(i)
随后做类内分位点 min-max 归一化到 [0,1]：
B(i) = clip( (B_raw(i) − q_low^c) / (q_high^c − q_low^c), 0, 1 )

【直觉解释】

若样本始终很难但 gap 没有变好（Δgap≈0 或 <0），Improve 低，B 不会高：避免把“学不会/噪声”当成信息量。

若样本 gap 改善明显但后期已远离边界（Hardness 低），B 也不会极高：避免把“纯简单样本”当作边界推进主力。

【超参数含义】

τ_g：边界附近的 gap 阈值（决定“难”的定义）

s_g：难度门控的平滑程度（控制分布是否易塌到 0/1）

τ_Δ：改善映射的温度（决定 Improve 的灵敏度）

T_e, T_l：早/后期窗口比例（与代理训练轮数匹配）

5.5 CoverageGainScore：覆盖增益得分（C）

【定位与目标】
CoverageGainScore 用于刻画“样本在子集层面带来的类内覆盖增益/去冗余价值”。它与 A、B 的差别在于：

A、B 偏单样本训练价值（吸收效率、边界推进）；

C 明确从“组合效应”角度评估：同一类别中，一个样本是否提供了与多数样本不同的混淆结构，从而为训练带来互补信息。

【输入与记录】
来自代理模型训练日志（.npz）：

每轮 logits：z_t(i)

标签：y_i

【计算步骤与数学形式】
（1）构造“混淆分布” q_t(i)
先得到 softmax 概率 p_t(k|i)。
对非真实类做归一化（把“错到哪里”当成分布）：
q_t(k|i) = p_t(k|i) / Σ_{j≠y_i} p_t(j|i), k≠y_i
并令 q_t(y_i|i)=0。

（2）对“边界附近轮次”加权汇聚（强调有效混淆信息）
仍使用基于 gap 的权重 α(t,i)（同 5.4）：
α(t,i) = σ( (τ_g − gap(t,i)) / s_g )
定义加权平均混淆向量：
Q(i) = ( Σ_t α(t,i) * q_t(i) ) / ( Σ_t α(t,i) + ε )

（3）类内 kNN 距离作为“覆盖增益”
在同一类别 c 内，对 {Q(i)} 做 kNN 平均距离：
d(i) = mean_{j∈kNN_c(i)} || Q(i) − Q(j) ||_2

d(i) 越大，表示该样本的混淆结构更独特，潜在互补性更强，冗余更低。

（4）类内分位点归一化
C(i) = clip( (d(i) − q_low^c) / (q_high^c − q_low^c), 0, 1 )

【超参数含义】

k：类内 kNN 的邻居数（控制“冗余/互补”的尺度）

τ_g, s_g：混淆加权的门控形状（与 5.4 保持一致）

q_low, q_high：鲁棒归一化分位点

5.6 RiskScore：极端噪声风险得分（R）

【定位与目标】
RiskScore 的角色是“极端噪声约束项”，只针对极少数明显异常样本施加惩罚，避免在简单数据集（如 CIFAR-10）上出现“伤及无辜”的大范围扣分。
R 的设计原则：
1）只惩罚上尾：只对类内最极端的高风险样本产生显著值；
2）平滑而非硬阈值：对阈值附近样本平滑过渡；
3）不追求覆盖所有困难样本：困难样本由 A/B/C 的正向信号来刻画，R 只管极端异常。

【输入与记录】
来自代理模型训练日志（.npz）：

每轮 loss：ℓ_t(i)

标签：y_i

【计算步骤与数学形式】
（1）后期窗口与 log 压缩
取后期窗口长度 E_l（默认末尾 20%，至少 5 轮）：
t ∈ T_l
\tildeℓ_t(i) = log(1 + ℓ_t(i))
LateLevel(i) = mean_{t∈T_l} \tildeℓ_t(i)

（2）类内稳健标准化
z_R(i) = robust_z( LateLevel(i) | y=c )

（3）类内上尾阈值 + 平滑门控（只惩罚极端）
对每类 c，取上尾分位点阈值：
thr_c = Quantile( z_R | y=c, p_r )
其中 p_r 通常取 0.95 或 0.97。

定义风险门控：
R_raw(i) = σ( ( z_R(i) − thr_{y_i} ) / τ_r )

解释：若 z_R(i) 低于类内上尾阈值，R_raw 接近 0；只有超过阈值的极端样本才快速上升。

（4）输出
R(i) = clip( R_raw(i), 0, 1 )


5.7 TransferGainScore：可迁移增益得分（T）

【定位与目标】
TransferGainScore（记为 T）用于显式引入验证集信息，但评价对象仍是“训练样本”。它刻画训练样本在被学习过程中，是否带来了同分布验证集上的可迁移改进，从而把“训练端的进展”与“验证端的收益”耦合起来。

T 的设计动机：
- 仅用训练轨迹（A/B/C/R）容易过拟合于训练子集的特殊性；
- OOF 验证轨迹提供了不泄露测试集的“预测视角”；
- 若某训练样本的学习推进与验证端同类样本的性能改善高度同步，则它更可能对应可泛化的知识（而非记忆/偶然拟合）。

【输入】
来自 K 折交叉验证日志（每折一个 fold_f.npz）：
- 训练子集 logits 轨迹：z_train^f[t, j, :]，j∈I_train^f
- 验证子集 logits 轨迹（OOF）：z_val^f[t, k, :]，k∈I_val^f
标签 y_i 通过 indices 回到原始数据集读取。

【计算步骤与数学形式（与实现对齐，强调“训练→验证耦合”）】

（1）验证端“类级改进曲线”
对验证样本先由 logits 得到真实类概率：
p_t(y|x) = softmax(z_val^f[t,x])_{y}

定义验证端的平滑损失（压缩长尾）：
ℓ_val^f(t, x) = log(1 + ( -log p_t(y_x|x) ))

对每个类别 c 构造验证端类均值曲线：
V^f(t, c) = mean_{x∈I_val^f, y_x=c} ℓ_val^f(t, x)

再定义“正向改进量”（只奖励下降）：
ΔV^f(t, c) = max( 0, V^f(t-1, c) - V^f(t, c) ),  t=2..E

（2）训练端“样本级推进曲线”（以 gap 的正向增量为主）
对训练样本 i（i∈I_train^f），定义：
gap^f(t,i) = p_t(y_i|i) - max_{k≠y_i} p_t(k|i)

其一阶差分：
Δgap^f(t,i) = gap^f(t,i) - gap^f(t-1,i)

为避免噪声与离散抖动，仅保留正向推进并做 softplus 平滑：
Δg^f_+(t,i) = τ_p · softplus( Δgap^f(t,i) / τ_p )

其中 τ_p 为温度（平滑“推进速度”的尺度）。

（3）耦合：样本推进与验证改进的对齐程度
令 c=y_i。将样本推进序列与“同类验证改进曲线”做归一化相关（或余弦相似度）：
T_raw^f(i) = corr( Δg^f_+(·,i),  ΔV^f(·,c) )

实现上可用：
T_raw^f(i) = <a,b> / (||a||·||b|| + ε),
其中 a=Δg^f_+(2..E,i)，b=ΔV^f(2..E,c)。

直觉：若样本 i 的训练推进主要发生在那些“验证端同类也同步受益”的 epoch，则 T 更高。

（4）跨折聚合与归一化
样本 i 会在 K−1 个折作为训练样本出现，得到 {T_raw^f(i)}。折间聚合：
T_raw(i) = median_f  T_raw^f(i)

最后做类内分位点 min-max（鲁棒）归一化：
T(i) = QuantileMinMax_class( T_raw(i) )

其中 QuantileMinMax_class 在训练集内对每类统计分位点标尺，并映射到 [0,1]。

【超参数含义】
τ_p：训练推进的平滑温度；越小越强调“瞬时推进”，越大越强调“累计推进”的稳定性
聚合方式（median/mean）：median 对单折异常更鲁棒
分位点归一化范围：默认 0.2%/99.8%（减少大量样本被压扁到 0/1 的风险）


5.8 PersistentDifficultyScore：持久难度得分（V）

【定位与目标】
PersistentDifficultyScore（记为 V）用于在验证/预测语境下鼓励难样本。与训练视角的“难但可推进”（B）不同，V 直接利用 OOF 验证轨迹刻画样本在训练后期仍然难以被稳定、高置信地区分的程度，并把这种“后期仍难”视为潜在价值，而不是噪声。

设计原则：
- 必须使用 OOF 验证轨迹，避免训练集视角的自证循环；
- 不对“尚未学会”的难样本做过强的可学性门控（噪声由其他分量共同抑制）；
- 聚焦训练后期（默认后 50% epoch），强调“持久难度”。

【输入】
对每个样本 i，仅使用其所在折的验证 logits 轨迹 z_val[t,i,:]（OOF）与标签 y_i。

【计算步骤与数学形式（后期窗口 + margin/entropy 双通道，m 与 h 权重相同，暂不引入稳定性项 S）】

（1）后期窗口
取后 50% epoch：
T_l = { ⌈0.5E⌉, ..., E−1 }.

（2）基于 margin 的后期难度（m 通道）
m_t(i) = z_val[t,i,y_i] − max_{c≠y_i} z_val[t,i,c]
将“margin 越小越难”映射为正向难度（平滑）：
d_m(t,i) = softplus( - m_t(i) / τ_m )

（3）基于预测不确定性的后期难度（h 通道）
由 softmax 得到概率 p_t(·|i)，定义熵：
H_t(i) = - Σ_c p_t(c|i) log(p_t(c|i)+ε)

将“越不确定越难”映射为正向难度（平滑）：
d_h(t,i) = softplus( ( H_t(i) - μ_H ) / τ_h )

其中 μ_H 可取该折验证集后期熵的中位数（或按类统计的中位数），用于把熵转为“相对不确定性”。

（4）后期聚合（m 与 h 等权）
V_raw(i) = mean_{t∈T_l}  ( 0.5·d_m(t,i) + 0.5·d_h(t,i) )

（5）类内分位点归一化
V(i) = QuantileMinMax_class( V_raw(i) )

解释：V 越大表示“在验证语境下后期仍持续困难/不确定”，从而被鼓励进入选择子集。

【超参数含义】
后期窗口比例（50%）：把“难”的定义锚定在训练充分推进之后，避免把早期的不稳定当成持久难度
τ_m：margin 难度的平滑温度
τ_h 与 μ_H：不确定性难度的尺度与中心化方式
分位点归一化范围：默认 0.2%/99.8%


5.9 综合动态效用标签 u_i（更新：加入 T 与 V）

本阶段的动态监督信号采用“加性融合 + 统一归一化”：

u_raw(i) = A(i) + B(i) + C(i) + w_T·T(i) + w_V·V(i) − R(i)

其中 w_T 与 w_V 为融合权重（默认取 1.0；调试时可取 0.25 作敏感性分析）。

随后对 {u_raw(i)} 做全局分位点 min-max 归一化到 [0,1]（与实现脚本一致）：

u(i) = clip( (u_raw(i) − q_low) / (q_high − q_low), 0, 1 )

其中 q_low/q_high 取 u_raw 的全局 0.2%/99.8% 分位点。

5.10 用 Ridge 回归学习静态评分权重

在得到综合动态效用标签 u(i) 之后，本阶段只使用静态特征向量

f_i = [ SA_i, Div_i, DDS_i ]^T

作为输入，不再直接依赖训练动态。记所有训练样本组成的静态特征矩阵为 X ∈ ℝ^{N×3}（第 i 行为 f_i），对应的目标向量为 u ∈ ℝ^N（第 i 个分量为 u(i)）。本项目采用带 L2 正则的线性回归（Ridge 回归）学习静态评分权重 w 和偏置 b，使得

û(i) = w^T f_i + b

尽可能拟合动态效用标签 u(i)。优化目标为

L(w, b) = (1 / N) · Σ_{i=1}^N ( w^T f_i + b − u(i) )^2 + λ · ||w||_2^2

其中 λ 为 ridge_lambda 超参数，用于控制权重的 L2 正则强度，防止在维度较少、样本数有限的情况下过拟合。

为保证评分函数的可解释性与跨数据集可比性，对权重 w 施加“非负且和为 1”的约束，将其视为 SA、Div、DDS 三个静态指标的组合权重：

w_k ≥ 0，Σ_{k=1}^3 w_k = 1。

实现上，采用简单的梯度迭代 + 概率单纯形投影方式求解：以均匀权重初始化 w（每一维约为 1/3），偏置 b 初始化为 u(i) 的全局均值；每次迭代先根据当前残差计算梯度，对 (w, b) 做一次梯度下降更新；随后将更新后的 w 投影到“概率单纯形”上，使其始终满足 w_k ≥ 0 且 Σ w_k = 1。当相邻两步的权重与偏置变化同时小于收敛阈值 tol，或达到最大迭代步数 max_iter 时停止。

最终得到的 w 用作本数据集上静态评分函数的固定权重，b 为对应的偏置项。对于不同随机种子 seed，脚本会分别运行一遍同样的权重学习流程，并把结果按数据集和 seed 写入 scoring_weights.json 以便后续实验统一调用。

六、最终评分函数与未见样本评估

6.1 最终评分定义

对任意样本 x（训练内或训练外），最终样本质量评分定义为：

Score(x) = ẇ_1 · SA(x) + ẇ_2 · Div(x) + ẇ_3 · DDS(x)

其中：

SA(x)：用 CLIP + Adapter 后特征 g(x) 与类别文本 t_y 的余弦相似度；

Div(x)：在 g(x) 所在类别的特征空间中，用 kNN 距离 rank 定义的相对稀疏度；

DDS(x)：在该类别基于 g(·) 做 PCA 得到的低方差方向上的投影幅度；

ẇ：前一阶段从训练动态学得的固定权重。

6.2 未见样本评分

对未见样本 x_new：

(1) 用 CLIP 图像编码器和 Adapter 得到 g_new；
(2) 用文本编码器得到类别嵌入 t_{y_new}，计算 SA_new；
(3) 将 g_new 插入对应类别的 G_c，计算 d_new → rank_new → Div_new；
(4) 用同类别的 μ_c 和 PCA 方向 u_k，计算 DDS_new；
(5) 用固定 ẇ 计算：

Score(x_new) = ẇ_1 SA_new + ẇ_2 Div_new + ẇ_3 DDS_new

整个过程不依赖训练动态，也不需重新训练模型。

七、基于 Score 的数据选择与 Selection Optimization

7.1 直接基于 Score 的排序选择

最直接使用方式：

对训练集中每个样本计算 Score(i)；

按 Score 排序，选取 top-k% 子集参与训练。

这实现了一个简单、直接的“样本质量驱动的数据裁剪”：高分样本保留、低分样本舍弃。

7.2 group 模式 — 基于裁剪比率的自适应遗传选择（Group selection via adaptive GA）

7.2.1 目的

在给定裁剪比例 cr（cut ratio）的条件下，从训练集中选取 target_size = round(cr * N) 个样本，使得在该子集 D 上计算的动态综合得分 S(D) 尽可能高。

要求算法在有限预算（典型 ga_generations = 120~200、时间约 6 分钟）内稳健工作，兼顾低 cr（强探索）与高 cr（稳健收敛）两类情形。

保持实现简单、可解释，易于复现实验与调参。

7.2.2 设计概览（一句话）

表示：固定大小的索引子集（indices）；适应度：在子集上重算的动态综合分；算子：父代交叉（inter/sym/complement）+ 随机变异 + 局部搜索；关键改进：4 档位周期退火的参数自适应（level-based），soft-fill 概率补样，以及对每代最优 offspring 做一次自洽（child-based）局部精修；停滞触发由连续 3 代无提升判定，降档或再升档形成周期退火。

个体表示为长度为 target_size 的整型数组 indices（或等效的 0/1 mask）；内部操作基于 indices 进行集合运算（交、并、补）。

种群由若干个体组成（ga_population_size，可小到 4~12）。种群中保留 fitness 最优个体（精英保存）。

7.2.3 适应度函数（Fitness）

适应度定义为子集 D 上的动态综合分：
S(D) = Σ_{i∈D} [ w_sa * SA_i + w_div * Div_i(D) + w_dds * DDS_i(D) ]

SA_i 为样本的静态得分，Div_i(D) 与 DDS_i(D) 为在 D 上的动态分量，需在 _real_stats_cached 中计算并缓存以避免重复开销。

评估流程应优先使用缓存键（基于排序的 indices tuple）以复用结果。

7.2.4 种群初始化（Initialization）

初始化使用两类个体混合：

一个或少数精英个体：按 SA 或静态综合（若需要）取 top-k；

其余个体：随机采样 target_size（以保证初期多样性）。

初始化时不要将 static_total 作为硬回填修复规则；static_total 可用作候选池（soft prior），但不应成为强制投影。

7.2.5 算子（Operators）
1 选择（Selection）

锦标赛选择（2-ary tournament）作为主选择机制，简单且高效。

2 交叉（Crossover）

父代 A, B → child：

inter = A ∩ B（保留公共基因）

sym = (A ∪ B) \ inter（父代差异）

child 先放 inter，再从 sym 按 need_sym 补部分，剩余从 complement_union 补齐。

need_sym 的上限由当代自适应 crossover_sym_ratio_eff 决定：max_from_sym = inter.size + floor(crossover_sym_ratio_eff * target_size)。

Soft-fill 替代硬 top-k：对 sym 或 complement 执行补样时，先构造一个候选池 pool = top_k_by_static(candidate, pool_mult * need)，再从 pool 中按概率（基于 rank 或 softmax）无放回采样 need 个，避免每次都取同一批样本（减少同质化）。推荐 pool_mult = 5，rank-based 权重 w(r) ∝ 1/(r+1)^γ，γ 默认 1。

3 变异（Mutation）

每代按 k_mut 随机替换 child 中 k_mut 个索引（从 complement 中随机选 k_mut）。k_mut 由当代自适应 mutation_ratio_eff × target_size 决定。

mutation_ratio 基线系数取 0.01（替代旧的 0.008），并按下述自适应档位映射为实际 ratio。

4 局部搜索（Local Search / Memetic）

两阶段局部搜索策略：

父代 proxy 本地搜索（现有）：在 child 生成后，使用父代更优者的 s_ref（在父代 D_parent 上计算）作为 proxy，对 child 做一次快速替换（按 proxy 挑出 child 内最差 k_ls，补入 complement 中 proxy 最好 k_ls），然后再评估 child。该步骤保留以提高效率。

本代最优 offspring 的自洽精修（新增）：在生成并评估所有 offspring 后，选出本代 fitness 最好的 offspring，用其自身的 s_ref（即基于 child 的真实 s_ref）做一次额外局部搜索与重新评估；若提升则替换，否则保持原样。此步骤每代额外最多一次完整动态评估（开销可接受）。

7.2.6 自适应调度（level-based 周期退火，4 档）

状态：level ∈ {0,1,2,3}（0 最收敛，3 最探索）。

预热：前 WARMUP=3 代依次升档（gen0→level1，gen1→level2，gen2→level3）。

瓶颈判定：连续 STALL_TRIGGER=3 代 best_S 无提升（提升阈值 EPS=1e-8）视为一次瓶颈事件。每遭遇一次（即 stall_counter 为 3、6、9…）执行一次档位更新：若 level>0 则 level -= 1（冷却）；若 level==0 则 level = 3（reheat）。当 best_S 有实质提升时把 stall_counter 置 0。

将参数映射到档位：对每个参数（local_search_ratio, mutation_ratio, crossover_sym_ratio）先计算其当代的最小/最大，然后在这段区间内等差分成 4 个档位值，直接选择 levels[level] 做为当代有效值（不用任何线性混合或连续缩放公式）。

参数边界

local_search_ratio：

ls_max(cr) = 0.06 − 0.03 × (cr / 100)

ls_min(cr) = 0.3 × ls_max(cr)

levels = 等差分成 4 档（L0 = ls_min, L3 = ls_max）

mutation_ratio：

m_max_mult(cr) = 2.0 + 3.0 × (1 − cr / 100)

mut_max = 0.01 × m_max_mult(cr)

mut_min = mut_max / 4

levels = 等差分成 4 档（M0 = mut_min, M3 = mut_max）

crossover_sym_ratio：

c_min(cr) = 0.7 − 0.2 × (cr / 100) （较小值表示更探索）

c_max = 0.95（常数上界）

levels = 等差分成 4 档，但交叉值与 level 方向反向：crossover_sym_ratio_eff = c_levels[3 − level]（level↑ → sym↓ → 更探索）

7.2.7 算法主循环（伪流程）

预计算并缓存静态分数（SA、静态 Div、静态 DDS）和必要的全局数组。

初始化 population（1 个 SA-top 精英 + 其余随机）。score_history = []。explore level 初值 1。stall_counter = 0。

For gen_idx in 0 .. ga_generations−1：

若 gen_idx < WARMUP：按预热规则设置 level。

依据 level / cr 计算三参数的当代有效值（mut_ratio_eff、ls_ratio_eff、crossover_sym_ratio_eff），并换算为 k_mut、k_ls、max_from_sym。

标准 GA: 生成 offspring（selection + crossover + soft-fill + mutation），对每个 child 做父代 proxy local_search，然后 _evaluate(child)（真实评估并缓存）。

对 offspring 中最优个体做一次自洽 local_search（child-s_ref），再 _evaluate，如提升则替换。

合并 population 与 offspring，按 fitness 排序保留前 ga_population_size；记录当代 best_S 到 score_history；更新 stall_counter（若 best_S 提升则置 0）。

若 stall_counter 达到 STALL_TRIGGER 的倍数，更新 level（冷却或 reheat）。

结束后对最终 best_mask 做一次 optional 精修（如需要），返回 mask 与统计信息。

7.2.8 实现要点与工程实践建议

缓存：_real_stats_cached 必须使用 canonical 且稳定的 key（如排序的 indices tuple）写缓存，避免重复计算。

soft-fill 池大小：pool_mult 取 5 足够；rank-based 权重用 w(r)=1/(r+1) 效果稳健。

日志：每代打印 gen_idx, level, k_mut, k_ls, crossover_sym_ratio_eff, best_S，便于诊断周期行为。

可控开关：把 --verbose 控制打印，默认关闭以节省 IO。

删除历史冗余：移除不再使用的 _shake() 实现与多 branch 轨迹记录（已在代码重构中清理）。

最小评估开销约束：自洽 local_search 只对每代最优 offspring 做 1 次，避免每个子代两次评估带来的线性开销翻倍。

种群内平均 Jaccard 相似度（可选）以衡量多样性

7.2.9 期望行为（经验上）

低 cr（20~30）会在预热期和初期快速上升，然后若卡在局部会通过降档→reheat 的周期机制跳出并尝试新的盆地；自洽 local_search 有望在 GA 给出的盆地边缘把解抬高一段。

高 cr（≥60）表现更稳定、后期以重组 + 局部细化为主，不会因初期过大步长而崩坏。

八、与直接使用训练动态评分的对比与方案意义

常见质疑：既然训练动态中已经有各种信息，为什么不直接把训练动态用作评分，而要多一层“静态指标 + 动态监督学习权重”的设计？

核心回答：

(1) 训练动态是“模型行为”，不是“样本固有属性”：

换模型、换初始化、换优化器、换 batch 顺序，动态模式都会改变；

对未见样本没有训练轨迹，无法直接给分；

仅用训练动态无法定义一个可复用的“样本质量模型”。

(2) 静态指标是“样本固有属性”：

基于 CLIP + Adapter 的语义对齐（SA）、类内相对稀疏度（Div）、类内难度方向（DDS）；

与训练过程无关，只与样本本身及其类别标签有关；

可以对任意新样本、任意新的训练过程复用。

(3) 我们的设计是：“训练动态做老师，静态评分函数做学生”：

训练动态通过 u_i 告诉我们：在这个具体任务中，哪类样本更有价值；

静态指标通过回归学习 ẇ，从而捕捉到“哪些静态特征模式对应高价值样本”；

一旦学成，静态评分函数 Score(·) 就可以在没有训练动态的情况下独立使用。

(4) Dataset Adapter 的引入进一步增强了这一框架：

Adapter 先对 CLIP 特征进行数据集适配，使 SA / Div / DDS 的统计结构更加合理；

Adapter 训练一次后固定，不与动态权重学习形成循环依赖；

对未见样本仍然可以直接前向 through adapter，然后用统一的 Score(·) 打分。

(5) 应用场景广泛而不是“很小的角落”：

自动构建和维护训练数据仓库：新增样本先打分，再决定是否加入训练集；

增强数据质量控制：对自动数据增强产生的样本、弱标或噪声数据进行质量筛选；

长期在线学习：在不断到来的数据流中有一个稳定的、与模型结构解耦的样本质量评价函数。

本项目交付的是一个“可解释、可泛化、可复用的样本质量评分函数”，而不仅仅是一套对某次训练日志的分析工具。

九、实现与实验规划简述

(1) 数据集：

CIFAR-10 / CIFAR-100 作为起点；

视时间可扩展到 Tiny-ImageNet 或 ImageNet 子集。

(2) 实现步骤：

使用预训练 CLIP 提取图像特征 f_i 与文本特征 t_y；

冻结 CLIP 主干，训练 Dataset Adapter，得到适配后特征 g_i；

基于 g_i 计算静态指标：SA_i / Div_i / DDS_i；

在原始图像上以 K 折交叉验证训练代理模型（ResNet-18），按折记录训练子集与验证子集（OOF）的 logits 轨迹；

基于训练轨迹计算 A/B/C/R，基于 OOF 验证轨迹计算 T（TransferGainScore）与 V（PersistentDifficultyScore），融合并归一化得到 u_i；

使用 Ridge 回归将 u_i 回归到 (SA_i, Div_i, DDS_i)，学习权重 w，得到 ẇ；

构造最终评分函数 Score(x)，对训练集与未见样本进行打分；

基于 Score 实现：

简单排序数据选择（不同选样比例）；

Selection Optimization（全局优化子集选择）；

将本方法与以下 baseline 对比：

使用全数据训练；

随机选择；

仅用单指标（如 SA 排序）；

经典方法（EL2N、MoSo 等）；

在不同噪声水平、不同数据规模、不同类别不平衡设置下评估：

分类准确率；

训练成本（epoch / 时间）；

选择子集的稳定性与可解释性；

学到的权重 ẇ 的差异及其合理性分析。

(3) 预期输出：

一套完整的样本评分与数据选择算法（含代码）；

实验结果表证明在同等选样比例下优于或不劣于已有方法；

一个可用于后续研究和工程实践的“样本质量评分函数”框架。

---

