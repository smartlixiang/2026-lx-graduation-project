一、项目定位与核心目标

1.1 问题背景

在图像分类任务中，训练集往往被当成“既定事实”：只要丢给模型训练即可。但现实中，数据集普遍存在这些问题：

含有噪声标注、低质量样本；

类内冗余严重，大量“长得差不多”的样本反复出现；

决策边界附近的关键样本比例不足；

难以评估后续新采集数据的价值。

传统数据选择／数据裁剪方法（如基于 loss、EL2N、GraNd、Forgetting、MoSo 等）有两个共性缺陷：

主要针对“已有训练集”，难以直接对未见样本打分；

强烈依赖特定训练过程和模型结构，缺乏可复用、可解释的“样本质量模型”。

plan

1.2 本项目的目标

本项目要做的不是简单的“再造一个数据选择算法”，而是设计一个面向图像分类任务的样本质量评估框架，具有以下能力：

(1) 给每个样本一个可解释的质量得分，明确区分“好样本”“一般样本”“坏样本”：

得分越高，表示语义更干净；

在类空间中覆盖更充分；

在类内关键变化方向上更有价值。

(2) 这个得分不仅能作用于当前训练集，还能对训练阶段未见的新样本进行快速评分：

新采集的数据不必重新训练就能知道“值不值得加入训练集”。

(3) 得分可以自然用于数据选择／数据裁剪：

例如指定只保留 top 50% 的高质量样本；

或在样本总量固定的约束下，用 Selection Optimization 选出最优子集。

(4) 权重学习：

静态指标本身是 train-free 的（基于 CLIP 特征和类内结构），但各指标的重要性会随数据集、任务而变化；

我们使用一次代理模型训练动态（loss、margin、forgetting）来学习这些静态指标的权重，得到一个“数据驱动”的评分模型；

训练动态只参与“教学”，不直接参与最终评分，保证最终评分函数能泛化到未见样本。

(5) 在静态指标之前引入轻量的 Dataset Adapter，对 CLIP 图像特征做数据集级的适配，使得静态指标在当前数据集上更稳定、更合理，同时不破坏对未见样本的泛化能力。

二、整体框架概览

从流程视角，整个框架可以分为四个阶段：

(0) 特征抽取与 Dataset Adapter 训练：

使用预训练 CLIP 的图像编码器和文本编码器；

冻结 CLIP 主体参数，训练一个轻量 Dataset Adapter，使图像特征在当前数据集上与类别语义更加对齐；

得到适配后的图像特征 g_i 作为静态指标的统一特征空间。

(1) 静态多指标评分（Static Scoring）：

基于 adapter 后的特征 g_i，构造三个 train-free 静态指标：

SA：语义对齐度（Semantic Alignment）；

Div：类内多样性覆盖度（基于 kNN 距离排序的 rank-based 稀疏度）；

DDS：类内难度方向得分（基于 PCA 的低方差方向投影）。

(2) 从训练动态学习权重（Weight Learning via Dynamics）：

在原始图像上训练一个代理分类模型（如 ResNet-18），记录每个样本的训练动态：early loss、margin 轨迹、forgetting 情况；

从这些动态构造三个 0–1 区间的动态指标：EarlyLossScore、MarginScore、ForgettingScore；

三者平均得到一个“样本效用标签” u_i；

用带 L2 正则的线性回归，将 u_i 回归到 (SA, Div, DDS)，学习出各静态指标的权重 w。

(3) 基于最终得分进行数据选择与 Selection Optimization：

最终评分定义为 Score(x) = Σ_k ẇ_k · feature_k，其中 ẇ 由 w 归一化而来；

直接用 Score 排序可以做简单数据选择；

进一步，在 Selection Optimization 中引入可学习的选择变量 d_i，在给定选样比例约束下，优化“整体被选子集的总 Score”。

整体实现了：

train-free 静态评分（可泛化到未见样本）；

利用一次训练动态学习权重（提高评分模型与任务的一致性）；

支持静态排序选择和基于优化的 Selection Optimization；

在静态指标前加入 Dataset Adapter，提升 CLIP 特征在目标数据集上的适配性。

三、Dataset Adapter 模块设计

3.1 设计目标

引入 Dataset Adapter 的目的：

适配预训练 CLIP 图像特征到当前数据集（如 CIFAR-10/100）的分布，使类内结构和类间语义更加清晰；

提升 SA、Div、DDS 这些静态指标在当前数据集上的表达质量；

仅在特征层做轻量变换，不改变 CLIP 主干参数；

不破坏“静态指标 → 动态监督 → 权重学习 → 静态评分函数”的整体逻辑；

对未见样本依然可直接前向计算 adapter 并评分。

3.2 结构形式

记 CLIP 图像编码器输出为 f_i ∈ ℝ^d（L2 归一化后）。我们设计一个轻量非线性 adapter：

g_i = Adapter(f_i) = W_2 · σ(W_1 f_i + b_1) + b_2

其中：

W_1 ∈ ℝ^{h×d}, W_2 ∈ ℝ^{d×h}，h 为瓶颈维度（如 256）；

σ 为非线性激活函数，可选 ReLU 或 GELU；

输出 g_i 再做一次 L2 归一化，以保持空间几何的稳定性。

特性：

参数量远小于 CLIP 主体，仅做“微调”而非彻底重学；

在类内局部分布上做平滑、对齐，有利于 PCA / kNN 这类结构性操作；

保留 CLIP 的语义结构，使 SA 更可信。

3.3 训练目标与流程

我们采用对比学习式的语义对齐目标，使 adapter 后的特征 g_i 更接近其标签文本嵌入 t_{y_i}：

文本特征：

t_c = CLIP_txt(prompt(c))，例如 prompt 为 “a photo of a [class name]”。

损失函数：

L_adapter = - log ( exp(cos(g_i, t_{y_i}) / τ) / Σ_{c=1}^C exp(cos(g_i, t_c) / τ) )

其中：

cos(·,·) 为余弦相似度；

τ 为温度系数（例如 0.07）；

C 为类别数。

训练过程：

(1) 冻结 CLIP 的所有参数，仅训练 Adapter 的 W_1, W_2, b_1, b_2；
(2) 在完整训练集上用上述损失训练若干 epoch（如 1–5 epoch），使图像特征与文本特征在当前数据集上更好对齐；
(3) 训练完成后固定 Adapter，后续所有静态指标与评分计算都基于 g_i，不再更新 adapter。

3.4 与后续模块的关系

顺序关系：

先训练 Adapter 并固定；

再基于 g_i 计算 SA、Div、DDS；

再训练代理分类模型并记录动态（此处用的是原始图像，不依赖 adapter）；

最后用动态构造 u_i，并用 (SA, Div, DDS) 回归 u_i 学习 w。

因此不存在“动态影响 adapter，再用动态监督静态指标”的循环依赖，逻辑清晰稳定。

对未见样本：

对新样本 x_new，先用 CLIP 提取 f_new，再经 Adapter 得到 g_new；

再基于 g_new 计算 SA_new / Div_new / DDS_new；

再用固定 ẇ 得到 Score(x_new)。

四、静态多指标样本评分模块（基于 adapter 后特征）

这一部分完全不依赖代理模型训练动态，是支撑“未见样本评分”的关键；也是后续动态权重学习的输入特征来源。

记：

训练样本 (x_i, y_i)；

CLIP 图像编码器输出 f_i，Dataset Adapter 输出 g_i（已 L2 归一化）；

CLIP 文本编码器对类别标签 y_i 的 prompt 输出 t_{y_i}。

所有静态指标均在 g_i 所在的特征空间中构建。

4.1 语义对齐度（Semantic Alignment, SA）

语义对齐度（Semantic Alignment, SA）用于度量样本图像内容与其标注类别语义之间的一致性。直观地说，如果一张图像确实属于类别 y_i，那么它在高维语义空间中应当更接近“该类别的语义描述”，而远离其他类别的语义描述。本项目基于冻结的 CLIP 图像编码器和文本编码器，在此基础上引入 Dataset Adapter，对图像侧特征进行数据集层面的轻量适配，并在适配后的特征空间中定义 SA 作为样本质量的一个核心指标。

本节首先给出基于余弦相似度的原始 SA 定义，然后在此基础上引入 margin 形式的改进版 SA，解释其设计动机、数学形式及实现方案。

（1）特征表示与基础设定

设 E_I(·) 为冻结的 CLIP 图像编码器，E_T(·) 为冻结的 CLIP 文本编码器。为适配目标数据集分布，在图像侧引入 Dataset Adapter A_I(·)，得到图像特征表示：

g_i = A_I(E_I(I_i)),

其中 I_i 为第 i 个图像样本，g_i ∈ R^d 为该样本在适配后语义空间中的特征表示。若未启用 Adapter，则有 g_i = E_I(I_i)。

对于类别 c，对其构造文本描述 prompt，例如：

T_c = "a photo of a " + 类别名称 c,

通过文本编码器获得类别语义嵌入：

t_c = E_T(T_c),

其中 t_c ∈ R^d。经过适当的归一化处理后，g_i 与 t_c 位于同一语义空间，可以使用余弦相似度直接刻画图像与类别语义之间的关系。

（2）原始 SA 定义：正类语义相似度（Cosine-based SA）

在最基础的设计中，语义对齐度 SA_i 定义为样本图像与其标注类别文本特征之间的余弦相似度：

SA_i^(cos) = cos(g_i, t_{y_i}),

其中 y_i 为样本 i 的标注类别。该定义反映了样本在语义空间中与“正确类别”之间的接近程度，具有以下特征：

1）形式简单、可解释性强：
SA_i^(cos) 越大，说明图像在语义空间上越接近其标注类别的文本描述，直观表示“图像语义与标签是否匹配”。

2）实现方便：
在实际实现中，只需对 g_i 和 t_{y_i} 做 L2 归一化，然后做一次点积即可得到 SA_i^(cos)。

然而，SA_i^(cos) 仅关注“图像与正类的相似度”，并未显式考虑“图像与其他类别的区分度”。在实际分类任务中，如果一个样本同时与多个类别都具有较高相似度，那么即使它对正类相似度较高，这个样本仍然是“语义模糊”或“容易混淆”的样本，属于质量可疑的样本类型。为增强 SA 对这种情况的敏感度，本项目在上述基础上进一步引入 margin 形式的语义对齐度。

（3）改进的 margin 语义对齐度（Margin-based SA）

为了同时刻画“对正类的贴合程度”和“与其他类别的区分程度”，本项目将 SA 定义为正类相似度与最相似负类相似度之间的差值，即 margin：

SA_i = cos(g_i, t_{y_i}) − max_{c ≠ y_i} cos(g_i, t_c).

其中：

1）cos(g_i, t_{y_i})：
表示样本在语义空间中与标注类别语义的贴合程度，越大越好。

2）max_{c ≠ y_i} cos(g_i, t_c)：
表示样本在“所有非标注类别”中，与其最相似的那个负类的语义相似度。如果这个值很高，说明该样本对其他类别也容易产生混淆。

因此，SA_i 的含义可以解释为：

SA_i 大：样本不仅与正类高度对齐，而且与所有负类保持足够间隔，语义清晰、标签可靠、视觉信息明确；

SA_i 小甚至为负：样本与正类的相似度有限，或与某个负类几乎一样接近，说明样本存在语义模糊、标注有问题、信息不足或噪声较重等情况。

与原始的 SA_i^(cos) 相比，margin 形式的 SA 具备以下优势：

1）更符合分类任务的判别逻辑：
分类问题的本质不仅是“与正确类别接近”，更是“与正确类别相比，和其他类别拉开足够差距”。margin 形式正是把这种“相对优势”显式量化出来。

2）对噪声样本和模糊样本更加敏感：
噪声样本往往在多个类别上都有较高相似度，此时 cos(g_i, t_{y_i}) 可能仍然不低，但 max_{c ≠ y_i} cos(g_i, t_c) 也会较高，导致 margin 下降。这样就能有效将“语义模糊样本”标记为低质量样本。

3）与 Adapter 训练目标保持一致：
Adapter 的训练过程本身就是通过对比学习提高正类对齐、削弱负类混淆。用 margin SA 作为质量指标，可以更自然地反映 Adapter 对“语义空间可分性”的改善。

4）可解释性更强：
对于某个样本，既可以查看 cos(g_i, t_{y_i}) 看是否“正类相似度不足”，也可以查看 max_{c ≠ y_i} cos(g_i, t_c) 看是否是“被某个负类强烈吸引”，从而给出更细粒度的分析。

（4）SA 的数学形式与实现步骤

在具体实现中，考虑一批样本的图像特征和全部类别的文本特征，定义：

G = [g_1; g_2; …; g_N] ∈ R^{N×d},
T = [t_1; t_2; …; t_C] ∈ R^{C×d},

其中每一行是一个 L2 归一化后的特征向量。通过矩阵乘法可一次性得到所有样本在所有类别上的余弦相似度：

S = G T^T ∈ R^{N×C}.

对于第 i 个样本，其标注类别为 y_i，则有：

1）正类相似度：
s_i^{(pos)} = S[i, y_i] = cos(g_i, t_{y_i}).

2）最相似负类相似度：
先在第 i 行中屏蔽掉列 y_i，对剩余列求最大值：
s_i^{(neg)} = max_{c ≠ y_i} S[i, c].

3）margin 式语义对齐度：
SA_i = s_i^{(pos)} − s_i^{(neg)}.

此过程可以通过简单而高效的张量操作实现：

使用矩阵乘法得到 S；

通过 gather 操作取出正类相似度；

构造布尔掩码屏蔽正类位置，在其余位置上求行最大值作为负类相似度；

二者相减得到 SA_i。

在代码中，SA 计算函数 _margin_similarity 即实现上述逻辑，支持批量计算并兼容不同设备（CPU/GPU）。

（5）原始 SA 与 margin SA 在项目中的关系

本项目在设计上同时保留“原始 SA（仅正类余弦）”和“margin SA（正类−最相似负类）”两种视角：

1）原始 SA（cosine-based）：
SA_i^(cos) = cos(g_i, t_{y_i})
主要用于直观评估“样本与其标签语义的正向契合程度”，在一些分析中可以直接使用这一简单指标，便于解释和展示。

2）margin SA（margin-based）：
SA_i = cos(g_i, t_{y_i}) − max_{c ≠ y_i} cos(g_i, t_c)
作为本项目实际使用的主版本 SA，用于样本质量评分、数据选择、以及后续与 SDS、DDS 等指标联合分析。它在反映样本“是否容易被其他类别混淆”方面具有更强的能力，更符合样本质量评估任务的需求。

在后续实验与分析中，本项目会以 margin SA 为主，必要时对比展示原始 SA^(cos)，以便分离“正类对齐问题”和“负类混淆问题”。

（6）归一化（更新：类内 1% 分位点 min-max 归一化，支持未见样本外推）

由于 SA 将与 Div、DDS 线性加权得到总分 Score，并进一步用于排序选择与未见样本质量评估，因此必须将 SA 映射到统一尺度 [0,1]。与传统的全局 min-max 不同，本项目采用“类内分位点 min-max”作为固定标尺：用训练集每个类别内部的 1% 与 99% 分位点作为有效范围端点，并对超界样本进行饱和截断，从而兼顾鲁棒性与可外推性。

记 SA 的原始 margin 分值为 SA_raw(i)，样本 i 的类别为 y_i=c。对每个类别 c，在训练集内收集该类所有 SA_raw，计算：

q_low^c = Quantile(SA_raw | y=c, 0.01)
q_high^c = Quantile(SA_raw | y=c, 0.99)

对属于类别 c 的任意样本 i（包括训练集样本与未见样本），定义类内归一化后的 SA 分数为：

SA_i = clip( (SA_raw(i) - q_low^c) / (q_high^c - q_low^c), 0, 1 )

其中 clip(·,0,1) 表示将结果截断到 [0,1] 区间；这意味着：

若 SA_raw(i) ≤ q_low^c，则 SA_i = 0（极低语义对齐样本）；

若 SA_raw(i) ≥ q_high^c，则 SA_i = 1（极高语义对齐样本）；

若 SA_raw(i) 处于 [q_low^c, q_high^c] 内，则线性映射到 (0,1) 区间，保留“幅度差异”。

数值退化处理：若某类出现 q_high^c ≈ q_low^c（该类 SA_raw 几乎为常数），则该类所有样本 SA_i 统一置为 0.5。

该归一化方式的优点在于：
1）尺度对齐：与 Div、DDS 同一 [0,1] 空间，便于线性加权；
2）鲁棒性：不受极端异常值影响（分位点而非 min/max）；
3）可外推：未见样本即使超出训练集范围，也会自然饱和到 0 或 1，不会产生不可控的 >1/<0。

4.2 多样性覆盖度 Div（基于 kNN 距离的 rank-based 稀疏度 + Normal-CDF 修正）

设计动机：

类内空间中越“稀疏”的样本，越可能提供新的变化信息和泛化收益；
我们希望构造一个对特征尺度不敏感、能跨数据集稳定对比的多样性指标；
因此采用“基于 kNN 距离的类内排序”，而非绝对距离阈值。

额外问题与改动动机：

原始 rank-based Div 的归一化是线性分位数（uniform quantile），即 Div 在同一类别内近似等间隔铺开。
在本项目中，Div 会与 SA、DDS 线性加权得到总分 Score，用于排序选择与后续 Selection Optimization。
若 Div 在 [0,1] 上近似均匀铺开，会导致“中等稠密区域”样本之间被过度细分：许多样本仅因 rank 的微小差异产生明显分数差，从而在总分中引入不必要的排序扰动。
更符合直觉的做法是：让“典型密度区域”的样本在 Div 上更集中（差异更小），而让“极端稀疏/极端密集”的样本更稀少（但仍保持可区分），即在 [0,1] 内形成“中间高、两端低”的分布形态。
因此在不改变类内排序意义（单调不变）的前提下，对 rank-based 分位数进行 Normal-CDF 形状修正，使 Div 的数值分布更符合“极端为少数、典型为多数”的使用目标。

(1) 特征空间构建

对每个样本使用 adapter 后特征 g_i（已 L2 归一化）；
对每个类别 c，收集该类的特征集合 G_c = { g_i | y_i = c }，样本数为 N_c。

(2) 计算类内 kNN 距离 d_i（更新：由 k-th 距离改为前 k 近均值）

对类别 c 内每个样本 i，记其适配后特征为 g_i。令 KNN_c(i) 表示在同类样本集合 G_c \ {g_i} 中，按欧氏距离从近到远选取的前 k 个最近邻样本索引集合：

KNN_c(i) = { j_1(i), j_2(i), …, j_k(i) }, 且 ||g_i − g_{j_1(i)}||2 ≤ … ≤ ||g_i − g{j_k(i)}||_2.

本项目将类内稀疏度的原始度量定义为“前 k 个最近邻距离的均值”：

d_i = (1/k) · Σ_{m=1..k} || g_i − g_{j_m(i)} ||_2.

直观解释：

在类内密集区域，样本周围的近邻更近，前 k 个距离整体更小 → d_i 小；

在类内稀疏区域，样本需要更远的范围才能找到足够近邻，前 k 个距离整体更大 → d_i 大。

与“第 k 个最近邻的单点距离（k-th distance）”相比，使用前 k 近均值具有更好的稳定性与鲁棒性：
1）对局部噪声更不敏感：单个异常近邻/远邻对均值的影响被平均化；
2）对密度不均更平滑：能更连续地刻画不同密度区域的差异；
3）更适合后续归一化：d_i 的数值分布更稳定，便于用分位点标尺映射到 [0,1]。

参数 k：
k 为全局固定超参数（如 k=10 或 k≈每类样本数的 10%），在所有类别上共享，用于控制局部密度估计的平滑程度。

(3) 将 d_i 转为相对稀疏度 rank_i

在类别 c 中，对所有 d_i 升序排序：
d_(1) ≤ d_(2) ≤ ... ≤ d_(N_c)
定义样本 i 的 rank_i 为其在排序中的位置（从 0 到 N_c − 1）；
rank_i 越大，代表样本越处于类内稀疏区域。

(4) 归一化（更新：不使用 rank 等间隔分位数）

为避免 rank 等间隔分位数将“距离幅度信息”抹平，同时保持指标尺度对齐与未见样本可评估性，本项目不再对类内 kNN 距离做排序赋分，而是直接在距离空间上采用类内分位点 min-max 归一化。

对类别 c 内每个样本 i，先得到 Div 的原始距离度量 Div_raw(i)=d_i（本方案中 d_i 为“同类前 k 个最近邻距离的均值”，见下文更新的 d_i 定义）。随后在训练集内对每个类别 c 统计该类所有 Div_raw：

q_low^c = Quantile(Div_raw | y=c, 0.01)
q_high^c = Quantile(Div_raw | y=c, 0.99)

并对属于类别 c 的任意样本 i 定义：

Div_i = clip( (Div_raw(i) - q_low^c) / (q_high^c - q_low^c), 0, 1 )

解释：

Div_i 越大表示样本处于更稀疏的类内区域（更可能提供新变化覆盖）；

分位点归一化抑制极端距离对尺度的破坏，并保留 1%~99% 区间内的幅度差异；

未见样本若更稀疏（距离超出 q_high^c），会直接得到 Div_i=1；若更密集（距离低于 q_low^c），则 Div_i=0。

数值退化处理与 SA 相同：若 q_high^c ≈ q_low^c，则该类 Div_i 统一置为 0.5。

(5) 未见样本的 Div_new（更新：对应均值距离 + 分位点标尺归一化）

对未见新样本 x_new（其类别为 c_new，若无真实标签可用预测标签代替）：
1）用冻结 CLIP 图像编码器与 Dataset Adapter 得到特征 g_new；
2）在训练阶段保存的该类特征集合 G_{c_new} 中，检索同类前 k 个最近邻集合 KNN_{c_new}(new)，计算原始距离均值：

Div_raw(new) = d_new = (1/k) · Σ_{m=1..k} || g_new − g_{j_m(new)} ||_2.

3）使用训练阶段在类别 c_new 上统计得到的分位点标尺 (q_low^{c_new}, q_high^{c_new})（分别为 1% 与 99% 分位点），进行类内归一化并截断：

Div_new = clip( (d_new − q_low^{c_new}) / (q_high^{c_new} − q_low^{c_new}), 0, 1 ).

该过程只需一次 kNN 查询与常数级归一化运算，不依赖训练动态信息；同时由于采用分位点标尺与截断，能够在未见样本距离超出训练集范围时仍稳定输出 [0,1] 分数（超出上界饱和为 1，低于下界饱和为 0）。

数值退化处理：若该类出现 q_high^{c_new} ≈ q_low^{c_new}，则 Div_new 置为 0.5，避免除零。

4.3 类内难度方向得分 DDS（Difficulty Direction Score）

目的：捕捉样本在类内“罕见但重要的变化方向”上的偏移，补充 SA（语义）与 Div（位置稀疏度）。

思路：

对每个类别单独在 adapter 后特征空间 G_c 上做 PCA；

类内低方差方向代表“少见但重要”的变化（例如特殊姿态、视角、光照等）；

在这些方向上偏移较大的样本，被视作具有较高“难度方向贡献”。

做法：

(1) 对每个类别 c，取 G_c 中所有特征 g_i，计算类内均值 μ_c。

(2) 对 G_c 做 PCA / 特征分解，得到主方向向量 {u_k} 及对应方差 λ_k，并按 λ_k 从小到大排序。

(3) 选择若干低方差方向，例如选择方差最小的前 K 个方向（K 可以是固定数，如 5–10，也可以基于阈值，比如累计方差小于某个比例）。

(4) 对类别为 c 的样本 i，定义：

DDS_i = Σ_{k ∈ low-variance} |⟨g_i − μ_c, u_k⟩|

性质：

DDS 高：样本在低方差方向上偏移较大，往往是“罕见但有价值的变化”，可能靠近类边界或覆盖少见模式；

DDS 低：样本在这些方向上接近类均值，更像“典型中心样本”。

归一化方案（类内分位点 min-max）：

DDS 的原始分值 DDS_raw(i) 由类内 PCA 的低方差方向投影定义（见前文）。由于不同类别的特征分布与方差结构差异较大，直接全局归一化会引入类间尺度偏置；同时，本项目要求对未见样本具备稳定的质量评估能力，因此 DDS 采用与 SA、Div 一致的“类内分位点 min-max”归一化。

对每个类别 c，在训练集内收集该类所有 DDS_raw，计算：

q_low^c = Quantile(DDS_raw | y=c, 0.01)
q_high^c = Quantile(DDS_raw | y=c, 0.99)

对属于类别 c 的任意样本 i（训练/未见均可）定义：

DDS_i = clip( (DDS_raw(i) - q_low^c) / (q_high^c - q_low^c), 0, 1 )

其中 clip(·,0,1) 表示饱和截断。数值退化处理同上：若 q_high^c ≈ q_low^c，则该类 DDS_i 统一置为 0.5。

该归一化在保证三指标统一尺度的同时，能够减少类间偏置，并使 DDS 在未见样本到来时无需重新统计全局 min/max，即可给出稳定可比的 [0,1] 评分。

***整体静态特征向量：

f_i = [ SA_i, Div_i, DDS_i ]^T

将作为后续动态权重学习的输入。

五、基于训练动态学习评分权重

5.1 问题动机

SA / Div / DDS 三个静态指标“谁更重要”，不同数据集与任务差异很大；

手工设权重（如平均加权）缺乏依据，超参数搜索又很耗时；

代理模型训练动态中包含“哪些样本对训练真正有用”的信息；

但训练动态本身依赖模型与训练过程，不能直接用于未见样本评分。

因此，本项目设计为：

用代理模型训练动态构造样本效用标签 u_i（0–1 的连续值）；

再用静态特征 f_i = (SA_i, Div_i, DDS_i) 回归 u_i；

学得一个可复用的静态评分函数 Score(·)。

训练动态是“老师”，静态指标是“学生”。

5.2 代理模型与记录

代理模型：如 ResNet-18，在完整训练集上训练 E 个 epoch；

训练在原始图像空间进行，与 CLIP/Adapter 模块分离；

在训练过程中，对每个样本 x_i 记录：

(1) 每轮 loss：ℓ_t(i)
(2) 每轮是否预测正确：c_t(i) ∈ {0,1}
(3) 每轮 logits：z_t(i) ∈ ℝ^C，用于计算 margin。

5.3 EarlyLossScore：早期损失指标

目的：度量训练初期样本的“难度”。

做法：

取前 E_e 个 epoch（例如 E_e = min(10, E/3)）；

对 loss 做稳健变换以抑制极端值，例如：

ℓ̃_t(i) = log(1 + ℓ_t(i)) 或 ℓ̃_t(i) = min(ℓ_t(i), ℓ_max)

计算早期平均损失：

L_i^early = (1 / E_e) Σ_{t=1}^{E_e} ℓ̃_t(i)

在所有样本上做 min-max 归一化，得到 EarlyLossScore_i ∈ [0,1]，值越大表示早期越难学。

5.4 MarginScore：基于 margin 的边界价值指标

目的：识别在训练过程中经常处于决策边界附近的“有效边界样本”。

做法：

(1) 定义每轮 margin：

m_t(i) = z_{t,y_i}(i) − max_{c≠y_i} z_{t,c}(i)

(2) 选择一个 margin 阈值 δ>0，根据 margin 和是否预测正确定义单轮评分 s_t(i)：

若 c_t(i) = 0（分错）：s_t(i) = −1；

若 c_t(i) = 1 且 m_t(i) ≤ δ：s_t(i) = +1（正确但靠近边界）；

若 c_t(i) = 1 且 m_t(i) > δ：s_t(i) = 0（正确且远离边界）。

(3) 对所有 epoch 取平均：

\bar s_i = (1 / E) Σ_{t=1}^E s_t(i) ∈ [−1, 1]

(4) 映射到 [0,1]：

MarginScore_i = ( \bar s_i + 1 ) / 2

解释：

经常被错分 → \bar s_i 接近 −1 → MarginScore 低；

经常正确且 margin 很大 → \bar s_i 接近 0 → MarginScore 中等偏低（典型易例）；

经常正确且 margin 接近阈值 → \bar s_i 接近 1 → MarginScore 高（典型边界样本）。

5.5 ForgettingScore：基于遗忘与正确率的稳定性指标

目的：区分以下几类样本：

难学但有价值：正确率低但不乱忘；

简单典型：正确率高且不乱忘；

噪声样本：正确率低且频繁遗忘；

不稳定坏样本：正确率高但频繁遗忘。

做法：

(1) 整体正确率：

r_i = (1 / E) Σ_{t=1}^E c_t(i) ∈ [0,1]

(2) 后半程遗忘次数：

在 t > E/2 的 epoch 范围内统计从 1→0 的转变次数：

F_i = #{ t ∈ (E/2, E−1] : c_t(i)=1 且 c_{t+1}(i)=0 }

(3) 将 F_i 做 min-max 归一化，得到 \tilde F_i ∈ [0,1]。

(4) 基于 (r_i, \tilde F_i) 定义 ForgettingScore_i = g(r_i, \tilde F_i) ∈ [0,1]，例如：

r_i 低、\tilde F_i 低：难学但不乱忘 → 高分（如 0.9）；

r_i 高、\tilde F_i 低：简单典型样本 → 中等偏上（如 0.7）；

r_i 低、\tilde F_i 高：难且乱忘 → 噪声疑似 → 低分（如 0.1）；

r_i 高、\tilde F_i 高：正确率高但不断遗忘 → 不稳定 → 低分（如 0.2）。

中间区域可以用线性插值，使 g(·,·) 连续。

5.6 综合动态效用标签 u_i

三项动态指标均在 [0,1] 后，取算术平均：

u_i = ( EarlyLossScore_i + MarginScore_i + ForgettingScore_i ) / 3

u_i 可视为代理模型对样本“综合训练价值”的连续软标签。

5.7 用 Ridge 回归学习静态评分权重

现在对每个样本 i，有：

静态特征：f_i = [ SA_i, Div_i, DDS_i ]^T；

动态目标：u_i ∈ [0,1]。

采用带 L2 正则的线性回归（Ridge Regression）学习 w ∈ ℝ^3, b：

\hat u_i = w^T f_i + b

损失：

L(w,b) = (1/N) Σ_i (w^T f_i + b − u_i)^2 + λ ||w||_2^2

约束：

所有待学习权重为正

训练完成后归一化：

ẇ_k = w'_k / Σ_j w'_j

得到归一化权重向量 ẇ = (ẇ_1, ẇ_2, ẇ_3)，代表 SA / Div / DDS 的相对重要性，由训练动态数据驱动确定。

六、最终评分函数与未见样本评估

6.1 最终评分定义

对任意样本 x（训练内或训练外），最终样本质量评分定义为：

Score(x) = ẇ_1 · SA(x) + ẇ_2 · Div(x) + ẇ_3 · DDS(x)

其中：

SA(x)：用 CLIP + Adapter 后特征 g(x) 与类别文本 t_y 的余弦相似度；

Div(x)：在 g(x) 所在类别的特征空间中，用 kNN 距离 rank 定义的相对稀疏度；

DDS(x)：在该类别基于 g(·) 做 PCA 得到的低方差方向上的投影幅度；

ẇ：前一阶段从训练动态学得的固定权重。

6.2 未见样本评分

对未见样本 x_new：

(1) 用 CLIP 图像编码器和 Adapter 得到 g_new；
(2) 用文本编码器得到类别嵌入 t_{y_new}，计算 SA_new；
(3) 将 g_new 插入对应类别的 G_c，计算 d_new → rank_new → Div_new；
(4) 用同类别的 μ_c 和 PCA 方向 u_k，计算 DDS_new；
(5) 用固定 ẇ 计算：

Score(x_new) = ẇ_1 SA_new + ẇ_2 Div_new + ẇ_3 DDS_new

整个过程不依赖训练动态，也不需重新训练模型。

七、基于 Score 的数据选择与 Selection Optimization

7.1 直接基于 Score 的排序选择

最直接使用方式：

对训练集中每个样本计算 Score(i)；

按 Score 排序，选取 top-k% 子集参与训练。

这实现了一个简单、直接的“样本质量驱动的数据裁剪”：高分样本保留、低分样本舍弃。

7.2 Selection Optimization：全局优化的样本选择

为缓解 group effect（个体分数高不代表组合最优），引入 Selection Optimization：将“选择哪些样本”视作一个可优化变量。

设计：

(1) 为每个样本 i 引入实值选择变量 d_i，令：

s_i = sigmoid(d_i) ∈ (0,1)

可解读为“选中程度”。

(2) 目标函数：

希望被选样本的总 Score 尽可能大；

希望被选样本比例接近目标比例 sr（如 0.5）。

定义：

L = − Σ_i s_i · Score(x_i) + β · L_ratio

其中：

L_ratio ≈ ( (1/N) Σ_i s_i − sr )^2

(可采用近似或直通估计器处理 s_i 的离散化需求。)

优化过程：

w 与静态指标已固定，Score(x_i) 固定；

针对 {d_i} 做梯度下降，更新 s_i，使目标 L 最小；

最终根据 s_i 的大小（例如阈值 0.5）来决定是否选取样本。

优势：

在给定的总比例约束下，选择的是“全局最优子集”，而不是简单 top-k；

自然考虑了样本之间的相互冗余与互补关系。

八、与直接使用训练动态评分的对比与方案意义

常见质疑：既然训练动态中已经有各种信息，为什么不直接把训练动态用作评分，而要多一层“静态指标 + 动态监督学习权重”的设计？

核心回答：

(1) 训练动态是“模型行为”，不是“样本固有属性”：

换模型、换初始化、换优化器、换 batch 顺序，动态模式都会改变；

对未见样本没有训练轨迹，无法直接给分；

仅用训练动态无法定义一个可复用的“样本质量模型”。

(2) 静态指标是“样本固有属性”：

基于 CLIP + Adapter 的语义对齐（SA）、类内相对稀疏度（Div）、类内难度方向（DDS）；

与训练过程无关，只与样本本身及其类别标签有关；

可以对任意新样本、任意新的训练过程复用。

(3) 我们的设计是：“训练动态做老师，静态评分函数做学生”：

训练动态通过 u_i 告诉我们：在这个具体任务中，哪类样本更有价值；

静态指标通过回归学习 ẇ，从而捕捉到“哪些静态特征模式对应高价值样本”；

一旦学成，静态评分函数 Score(·) 就可以在没有训练动态的情况下独立使用。

(4) Dataset Adapter 的引入进一步增强了这一框架：

Adapter 先对 CLIP 特征进行数据集适配，使 SA / Div / DDS 的统计结构更加合理；

Adapter 训练一次后固定，不与动态权重学习形成循环依赖；

对未见样本仍然可以直接前向 through adapter，然后用统一的 Score(·) 打分。

(5) 应用场景广泛而不是“很小的角落”：

自动构建和维护训练数据仓库：新增样本先打分，再决定是否加入训练集；

增强数据质量控制：对自动数据增强产生的样本、弱标或噪声数据进行质量筛选；

长期在线学习：在不断到来的数据流中有一个稳定的、与模型结构解耦的样本质量评价函数。

本项目交付的是一个“可解释、可泛化、可复用的样本质量评分函数”，而不仅仅是一套对某次训练日志的分析工具。

九、实现与实验规划简述

(1) 数据集：

CIFAR-10 / CIFAR-100 作为起点；

视时间可扩展到 Tiny-ImageNet 或 ImageNet 子集。

(2) 实现步骤：

使用预训练 CLIP 提取图像特征 f_i 与文本特征 t_y；

冻结 CLIP 主干，训练 Dataset Adapter，得到适配后特征 g_i；

基于 g_i 计算静态指标：SA_i / Div_i / DDS_i；

在原始图像上训练代理模型（ResNet-18），记录训练动态（loss / c_t / logits）；

计算 EarlyLossScore_i / MarginScore_i / ForgettingScore_i，并构造 u_i；

使用 Ridge 回归将 u_i 回归到 (SA_i, Div_i, DDS_i)，学习权重 w，得到 ẇ；

构造最终评分函数 Score(x)，对训练集与未见样本进行打分；

基于 Score 实现：

简单排序数据选择（不同选样比例）；

Selection Optimization（全局优化子集选择）；

将本方法与以下 baseline 对比：

使用全数据训练；

随机选择；

仅用单指标（如 SA 排序）；

经典方法（EL2N、MoSo 等）；

在不同噪声水平、不同数据规模、不同类别不平衡设置下评估：

分类准确率；

训练成本（epoch / 时间）；

选择子集的稳定性与可解释性；

学到的权重 ẇ 的差异及其合理性分析。

(3) 预期输出：

一套完整的样本评分与数据选择算法（含代码）；

实验结果表证明在同等选样比例下优于或不劣于已有方法；

一个可用于后续研究和工程实践的“样本质量评分函数”框架。