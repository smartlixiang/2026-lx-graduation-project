一、项目定位与核心目标

1.1 问题背景

在图像分类任务中，训练集往往被当成“既定事实”：只要丢给模型训练即可。但现实中，数据集普遍存在这些问题：

含有噪声标注、低质量样本；

类内冗余严重，大量“长得差不多”的样本反复出现；

决策边界附近的关键样本比例不足；

难以评估后续新采集数据的价值。

传统数据选择／数据裁剪方法（如基于 loss、EL2N、GraNd、Forgetting、MoSo 等）有两个共性缺陷：

主要针对“已有训练集”，难以直接对未见样本打分；

强烈依赖特定训练过程和模型结构，缺乏可复用、可解释的“样本质量模型”。

1.2 本项目的目标

本项目要做的不是简单的“再造一个数据选择算法”，而是设计一个面向图像分类任务的样本质量评估框架，具有以下能力：

1）给每个样本一个可解释的质量得分，明确区分“好样本”“一般样本”“坏样本”：

得分越高，表示语义更干净、对类空间覆盖更充分、在类内关键变化方向上更有价值。

2）这个得分不仅能作用于当前训练集，还能对训练阶段未见的新样本进行快速评分：

新采集的数据不必重新训练就能知道“值不值得加入训练集”。

3）得分可以自然用于数据选择／数据裁剪：

例如指定只保留 top 50% 的高质量样本；

或指定总样本量固定下，用 Selection Optimization 选出最优子集。

4）权重学习：

静态指标本身是 train-free 的（CLIP 特征、类内结构），但各指标的重要性会随数据集、任务而变化；

我们使用一次代理模型训练动态（loss、margin、forgetting）来学习这些静态指标的权重，得到一个“数据驱动”的评分模型；

训练动态只参与“教学”，不直接参与最终评分，保证最终评分函数能泛化到未见样本。

二、整体框架概览

框架核心流程可以概括为三个阶段：

（1）静态多指标评分：对每个样本计算三个 train-free 静态指标：

SA：语义对齐度（CLIP image–text similarity）；

Div：类内多样性覆盖度（ε-sample-cover 风格）；

DDS：类内难度方向得分（基于 PCA 的低方差方向投影）。

（2）从训练动态学习权重：

训练一个代理分类模型（如 ResNet-18），记录每个样本的训练动态：early loss、margin 轨迹、forgetting 情况；

从这些动态构造三个 0–1 区间的“动态评分”指标：EarlyLossScore、MarginScore、ForgettingScore；

三者平均得到一个“样本效用标签” u_i；

用带 L2 正则的线性回归，将 u_i 回归到（SA, Div, DDS），学习出各静态指标的权重 w。

（3）基于最终得分进行数据选择与 Selection Optimization：

最终评分定义为 Score(x) = Σ_k ẇ_k · feature_k，其中 ẇ 由 w 归一化而来；

直接用 Score 排序可以做简单数据选择；

进一步，在 Selection Optimization 中引入可学习的选择变量 d_i，在给定选样比例约束下，优化“整体被选子集的总 Score”。

整个框架实现了：

train-free 静态评分（可泛化到未见样本）；

一次性利用训练动态学习权重（提高评分模型与任务的一致性）；

支持静态选择和优化选择（Selection Optimization）。

三、静态多指标样本评分模块

这部分完全不依赖代理模型训练动态，是支撑“未见样本评分”的关键。

记训练样本为 (x_i, y_i)，CLIP 的图像编码器输出 f_img(x_i)，文本编码器对类别标签 y_i 的描述输出 f_txt(y_i)。所有静态指标均在 CLIP 特征空间构建。

3.1 语义对齐度 SA（Semantic Alignment）

目的：衡量样本图像与其类别语义是否一致，抑制噪声与误标。

做法：

为每个类别 y 构造文本 prompt，如 “a photo of a [class name]”；

使用 CLIP 编码图像和文本，得到向量：

v_img = CLIP_img(x_i)

v_txt = CLIP_txt(y_i)

定义 SA：
SA_i = cos(v_img, v_txt)

性质：

SA 高：图像与标签语义高度一致，通常是干净、典型样本；

SA 低：可能是噪声样本、误标样本或者极端异常样本。

SA 对未见样本天然适用（CLIP 是预训练多模态模型）。

3.2 多样性覆盖度 Div（Diversity）

目的：衡量样本在类内特征空间中是否位于稀疏区域，提供“覆盖新区域”的能力，而不仅仅重复已有样本。

思路：借鉴 ε-sample-cover 思想，用局部密度反向表征多样性。

做法（以类内为单位）：

1）在 CLIP 特征空间中，对同一类别 y 的样本集合计算特征向量 {f_i}。

2）对每个样本 x_i，估计其局部密度 density(x_i)：

可使用 kNN：计算到其同类样本 k 近邻的平均距离 d_k(i)，然后定义
density(x_i) = 1 / (d_k(i) + ε_0)，ε_0 为平滑常数；

或用核密度估计，核心思想相同。

3）定义多样性得分（密度的反函数）：
Div_i = exp( - density(x_i) / ε )
或者直接采用 monotonic transform，使得：

位于类内密集区域（典型样本） → density 高 → Div 低；

位于边缘或者稀疏区域 → density 低 → Div 高。

解释：

Div 不意味着“距类中心越远越好”，而是看它是否出现在“少见但合理”的区域；

当结合 SA 使用时，Div 高且 SA 不低的样本，往往是“类内有价值的变化”。

3.3 类内难度方向得分 DDS（Difficulty Direction Score）

目的：捕捉样本在类内“罕见但重要的变化方向”上的投影，补充 SA 和 Div。

思路：

对每个类别单独做 PCA，类内低方差方向代表相对罕见的变化；

在这些方向上投影幅度大的样本，可以视作“提供类内关键变化”的样本。

做法：

1）对每个类别 y，取该类所有样本的 CLIP 特征 {f_i}，计算类均值 μ_y。

2）在该类上做 PCA，得到特征向量 {u_k} 及对应方差 λ_k。将方差从小到大排序。

3）选取若干“低方差方向”（如取最小的前 K 个 λ_k），这些方向对应“少见变化”。

4）对类别为 y 的样本 x_i，定义
DDS_i = Σ_{k ∈ low-var} |⟨f_i - μ_y, u_k⟩|

性质：

DDS 高：样本在类内罕见方向上有较大偏移，即在某种“少见视角／姿态／风格”上提供重要信息；

DDS 低：样本在这些方向上接近均值，类似“普通典型样本”。

SA、Div、DDS 三者是互补的：

SA：语义是否干净／对齐；

Div：是否覆盖新的类内区域；

DDS：是否覆盖类内难度方向上的罕见变化。

四、基于训练动态学习评分权重

问题动机：

SA / Div / DDS 三个静态指标“谁更重要”，不同数据集、不同任务差异很大；

单纯凭经验设 w = (1,1,1) 或做网格搜索既缺乏理论依据，又耗费大量算力；

代理模型训练动态中隐含了“哪些样本对训练真正有用”的信息，但训练动态本身不能直接用于评分（依赖模型、过程、无法用于未见样本）。

于是我们的设计是：

用代理模型训练动态构造一个样本效用标签 u_i（0–1）；

再用 (SA_i, Div_i, DDS_i) 回归 u_i，学习一个可复用的静态评分函数。

训练动态相当于“老师”，静态指标是“学生”。

4.1 代理模型与记录

选择一个中等规模的代理分类模型，例如 ResNet-18，在完整训练集上训练 E 个 epoch。

在训练过程中，对每个样本 x_i 记录：

每轮 loss：ℓ_t(i)

每轮是否预测正确：c_t(i) ∈ {0,1}

每轮 logits：z_t(i) ∈ ℝ^C，用于计算 margin。

4.2 EarlyLossScore：早期损失指标

目的：度量训练初期样本的“难度 уровня”。

做法：

取前 E_e 个 epoch（例如 E_e=10），对 loss 做稳健变换：
ℓ̃_t(i) = log(1 + ℓ_t(i)) 或 min(ℓ_t(i), ℓ_max)

计算早期平均损失：
L_i^early = (1 / E_e) Σ_{t=1}^{E_e} ℓ̃_t(i)

在所有样本上做 min-max 归一化：
EarlyLossScore_i ∈ [0,1]，值越大表示早期越难学。

4.3 MarginScore：基于 margin 的边界价值指标

目的：识别那些在训练过程中频繁处于决策边界附近的“有效边界样本”。

做法：

1）定义每轮 margin：
m_t(i) = z_{t, y_i}(i) - max_{c≠y_i} z_{t, c}(i)

2）设定一个 margin 阈值 δ > 0。对每一轮给出评分 s_t(i)：

若 c_t(i)=0（分错）：s_t(i) = -1；

若 c_t(i)=1 且 m_t(i) ≤ δ（刚好分对但接近边界）：s_t(i) = +1；

若 c_t(i)=1 且 m_t(i) > δ（高度自信地分对）：s_t(i) = 0。

3）对全训练过程求平均：
\bar s_i = (1/E) Σ_{t=1}^E s_t(i) ∈ [-1,1]

4）映射到 [0,1]：
MarginScore_i = (\bar s_i + 1)/2

解释：

经常被错分 → \bar s_i 接近 -1 → MarginScore 低；

经常正确且 margin 很大 → \bar s_i 接近 0 → MarginScore 中等偏低（典型易例）；

经常正确但 margin 总处在阈值附近 → \bar s_i 接近 1 → MarginScore 高（典型边界样本）。

4.4 ForgettingScore：基于后半程遗忘与正确率的稳定性指标

目的：综合考察样本在训练后半程的稳定性与模型是否“真正掌握”该样本，从而区分：

难学但有价值的样本（难但不乱忘）；

简单典型样本；

噪声样本（难且乱忘）；

学得不稳定的坏样本（正确率高但不断遗忘）。

做法：

1）整体正确率：
r_i = (1/E) Σ_{t=1}^E c_t(i) ∈ [0,1]

2）后半程遗忘次数：
在 t > E/2 的 epoch 中统计从 1 变 0 的次数：
F_i = #{t ∈ (E/2, E-1] : c_t(i)=1, c_{t+1}(i)=0}

3）将 F_i 归一化到 [0,1] 得 \tilde F_i。

4）根据 (r_i, \tilde F_i) 定义一个映射 g(r_i, \tilde F_i) → [0,1]，可以采用“分区+简单插值”的逻辑，例如：

r 低、\tilde F 低：难学但不乱忘 → 高分（例如 0.9）

r 高、\tilde F 低：简单典型样本 → 中等偏上（如 0.7）

r 低、\tilde F 高：难且乱忘 → 噪声疑似 → 低分（如 0.1）

r 高、\tilde F 高：正确率高但经常忘 → 不稳定 → 低分（如 0.2）

通过这样的设计，ForgettingScore_i ∈ [0,1]，显式编码了“难、稳、乱”的差异。

4.5 综合动态效用标签 u_i

将三个 0–1 指标取算术平均：
u_i = (EarlyLossScore_i + MarginScore_i + ForgettingScore_i) / 3

u_i 可以理解为：在代理模型训练过程中，模型“认为”这个样本对最终决策的综合价值。它不是最终评分，而是训练动态对样本价值的一个“软标签”。

4.6 用 Ridge 回归学习静态评分权重

现在我们有：

输入特征 f_i = (SA_i, Div_i, DDS_i)（静态特征）；

目标标签 u_i ∈ [0,1]（动态效用）。

我们使用带 L2 正则的线性回归（Ridge Regression）：

目标：
\hat u_i = w^T f_i + b

损失：
L(w, b) = (1/N) Σ_i (w^T f_i + b - u_i)^2 + λ ||w||_2^2

训练后得到 w, b。为了便于解释与使用：

对 w 做非负截断：w'_k = max(w_k, 0)；

再归一化：
ẇ_k = w'_k / Σ_j w'_j

最终得到归一化权重向量 ẇ = (ẇ_1, ẇ_2, ẇ_3)，代表 SA / Div / DDS 在该数据集上的相对重要性，由训练动态“数据驱动”决定。

五、最终评分函数与未见样本评估

5.1 最终评分定义

对任意样本 x（包含训练内和训练外），其最终样本质量评分定义为：
Score(x) = ẇ_1 · SA(x) + ẇ_2 · Div(x) + ẇ_3 · DDS(x)

其中：

SA(x)：直接用 CLIP 对 x 与其标签文本编码计算；

Div(x)：用 x 在 CLIP 特征空间中的局部密度（相对类内样本）计算；

DDS(x)：用类内 PCA 得到的低方差方向，对 (f(x) - μ_y) 投影求和；

ẇ：前一阶段从训练动态学得的固定权重。

5.2 未见样本评分

对未见样本 x_new：

不需要训练任何新模型，也不需要其训练动态；

只要能：

通过 CLIP 得到 f_img(x_new)；

已有类内 μ_y、PCA 方向、密度估计；

就可以完全同样地计算 SA(x_new)、Div(x_new)、DDS(x_new)，再套用固定 ẇ，得到 Score(x_new)。

这就是整个设计中“静态评分 + 动态学权重”的最大价值：

训练动态只用一次，用来教会“静态指标如何加权”；

真正用来评分和部署的是静态评分函数，本身不依赖训练过程。

六、基于 Score 的数据选择与 Selection Optimization

6.1 直接基于 Score 的排序选择

最简单的使用方式：

对训练集所有样本计算 Score(i)；

直接排序、选取 top-k%，作为训练子集。

这一步本质是将各种复杂因素（语义干净度、多样性、类内难度方向）统一到一个标量上，方便工程使用。

6.2 Selection Optimization：优化级的数据选择

为了进一步解决 group effect 问题（“个体分数高不代表一起选就最优”），采用 Selection Optimization 思路：

1）为每个样本引入选择变量 d_i（实值）：
s_i = sigmoid(d_i) ∈ (0,1)，视为被选概率或软选择权重。

2）目标函数：

希望被选样本的总 Score 尽可能大；

同时满足总选样比例接近预设 sr（例如 sr=0.5）。

可定义优化目标：
L = - Σ_i s_i · Score(x_i) + β · L_s

其中 L_s 为比例约束项，例如：
L_s = ( (1/N) Σ_i I(s_i>0.5) - sr )^2 的近似可微版本，用 STE（Straight-Through Estimator）处理离散化。

3）在优化中：

w 已固定，Score(x_i) 已确定；

唯一学习的是 d_i；

训练结束后，将 s_i 二值化（如阈值 0.5），得到最终选中的子集。

Selection Optimization 相比直接排序的优势在于：

考虑了样本之间的相互作用；

可以在全局层面优化“整体子集”的质量，而不是局部贪心地选 top-k 个个体。

七、与直接使用训练动态评分的对比与本方案的意义

常见质疑：“既然代理模型的训练动态已经能定义样本价值，为什么不直接用动态评分，而要绕一圈去拟合静态指标？”

核心回答：

1）训练动态是模型行为，不是样本固有属性：

换模型、换初始化、换优化器，动态模式会变；

对未见样本没有训练轨迹，无法直接打分；

所以动态本身不适合作为“最终评分函数”。

2）静态指标是样本固有属性：

来自 CLIP 语义、多样性结构、类内几何结构；

与训练过程无关，只与样本及类别标签有关；

可以对任意新样本、任意新训练过程复用。

3）我们的设计是让“动态做老师，静态做学生”：

动态通过 u_i 告诉我们：“在这个任务中，这类样本更有用”；

静态指标通过回归学习，使评分函数捕捉到这些规律；

一旦学成，静态评分函数可以独立工作，为未来的新样本服务。

4）场景并不“很小”，反而是数据中心 AI 的关键能力：

自动构建优质训练集时，需要评估新采集样本是否值得加入；

数据增强、弱标注场景中，需要对合成样本、弱标样本评估质量；

长期维护一个不断扩充的数据仓库时，需要一个稳定的、模型无关的“样本质量度量”。

本项目要交付的正是这样一个“样本评分模型（scoring function）”，而不是一次性的“训练记录分析”。

八、实现与实验规划简述（可以后续细化）

1）数据集：CIFAR-10 / CIFAR-100 起步，后续可扩展到 Tiny-ImageNet / ImageNet 子集。

2）实现步骤：

用 CLIP 提取图像特征与文本特征，计算 SA；

在特征空间内按类计算密度与 PCA，得到 Div 和 DDS；

训练代理模型，记录 loss / c_t / logits；

计算 EarlyLossScore / MarginScore / ForgettingScore，并得到 u_i；

用 Ridge 回归学习 w，构造最终 Score；

基于 Score 做排序数据选择与 Selection Optimization；

与现有方法（随机、loss-based、EL2N、MoSo 等）在相同选样比例下比较精度、收敛速度等。

3）指标：

分类 Top-1 准确率；

训练成本（epoch 数、训练时间）；

在噪声、类不平衡等设置下的鲁棒性表现；

不同数据集上学到的权重 ẇ 的可解释分析。