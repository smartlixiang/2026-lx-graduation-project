一、项目定位与核心目标

1.1 问题背景

在图像分类任务中，训练集往往被当成“既定事实”：只要丢给模型训练即可。但现实中，数据集普遍存在这些问题：

含有噪声标注、低质量样本；

类内冗余严重，大量“长得差不多”的样本反复出现；

决策边界附近的关键样本比例不足；

难以评估后续新采集数据的价值。

传统数据选择／数据裁剪方法（如基于 loss、EL2N、GraNd、Forgetting、MoSo 等）有两个共性缺陷：

主要针对“已有训练集”，难以直接对未见样本打分；

强烈依赖特定训练过程和模型结构，缺乏可复用、可解释的“样本质量模型”。

plan

1.2 本项目的目标

本项目要做的不是简单的“再造一个数据选择算法”，而是设计一个面向图像分类任务的样本质量评估框架，具有以下能力：

(1) 给每个样本一个可解释的质量得分，明确区分“好样本”“一般样本”“坏样本”：

得分越高，表示语义更干净；

在类空间中覆盖更充分；

在类内关键变化方向上更有价值。

(2) 这个得分不仅能作用于当前训练集，还能对训练阶段未见的新样本进行快速评分：

新采集的数据不必重新训练就能知道“值不值得加入训练集”。

(3) 得分可以自然用于数据选择／数据裁剪：

例如指定只保留 top 50% 的高质量样本；

或在样本总量固定的约束下，用 Selection Optimization 选出最优子集。

(4) 权重学习：

静态指标本身是 train-free 的（基于 CLIP 特征和类内结构），但各指标的重要性会随数据集、任务而变化；

我们使用一次代理模型训练动态（loss、margin、forgetting）来学习这些静态指标的权重，得到一个“数据驱动”的评分模型；

训练动态只参与“教学”，不直接参与最终评分，保证最终评分函数能泛化到未见样本。

(5) 在静态指标之前引入轻量的 Dataset Adapter，对 CLIP 图像特征做数据集级的适配，使得静态指标在当前数据集上更稳定、更合理，同时不破坏对未见样本的泛化能力。

二、整体框架概览

从流程视角，整个框架可以分为四个阶段：

(0) 特征抽取与 Dataset Adapter 训练：

使用预训练 CLIP 的图像编码器和文本编码器；

冻结 CLIP 主体参数，训练一个轻量 Dataset Adapter，使图像特征在当前数据集上与类别语义更加对齐；

得到适配后的图像特征 g_i 作为静态指标的统一特征空间。

(1) 静态多指标评分（Static Scoring）：

基于 adapter 后的特征 g_i，构造三个 train-free 静态指标：

SA：语义对齐度（Semantic Alignment）；

Div：类内多样性覆盖度（基于 kNN 距离排序的 rank-based 稀疏度）；

DDS：类内难度方向得分（基于 PCA 的低方差方向投影）。

(2) 从训练动态学习权重（Weight Learning via Dynamics）：

在原始图像上训练一个代理分类模型（如 ResNet-18），记录每个样本的训练动态：early loss、margin 轨迹、forgetting 情况；

从这些动态构造三个 0–1 区间的动态指标：EarlyLossScore、MarginScore、ForgettingScore；

三者平均得到一个“样本效用标签” u_i；

用带 L2 正则的线性回归，将 u_i 回归到 (SA, Div, DDS)，学习出各静态指标的权重 w。

(3) 基于最终得分进行数据选择与 Selection Optimization：

最终评分定义为 Score(x) = Σ_k ẇ_k · feature_k，其中 ẇ 由 w 归一化而来；

直接用 Score 排序可以做简单数据选择；

进一步，在 Selection Optimization 中引入可学习的选择变量 d_i，在给定选样比例约束下，优化“整体被选子集的总 Score”。

整体实现了：

train-free 静态评分（可泛化到未见样本）；

利用一次训练动态学习权重（提高评分模型与任务的一致性）；

支持静态排序选择和基于优化的 Selection Optimization；

在静态指标前加入 Dataset Adapter，提升 CLIP 特征在目标数据集上的适配性。

三、Dataset Adapter 模块设计

3.1 设计目标

引入 Dataset Adapter 的目的：

适配预训练 CLIP 图像特征到当前数据集（如 CIFAR-10/100）的分布，使类内结构和类间语义更加清晰；

提升 SA、Div、DDS 这些静态指标在当前数据集上的表达质量；

仅在特征层做轻量变换，不改变 CLIP 主干参数；

不破坏“静态指标 → 动态监督 → 权重学习 → 静态评分函数”的整体逻辑；

对未见样本依然可直接前向计算 adapter 并评分。

3.2 结构形式

记 CLIP 图像编码器输出为 f_i ∈ ℝ^d（L2 归一化后）。我们设计一个轻量非线性 adapter：

g_i = Adapter(f_i) = W_2 · σ(W_1 f_i + b_1) + b_2

其中：

W_1 ∈ ℝ^{h×d}, W_2 ∈ ℝ^{d×h}，h 为瓶颈维度（如 256）；

σ 为非线性激活函数，可选 ReLU 或 GELU；

输出 g_i 再做一次 L2 归一化，以保持空间几何的稳定性。

特性：

参数量远小于 CLIP 主体，仅做“微调”而非彻底重学；

在类内局部分布上做平滑、对齐，有利于 PCA / kNN 这类结构性操作；

保留 CLIP 的语义结构，使 SA 更可信。

3.3 训练目标与流程

我们采用对比学习式的语义对齐目标，使 adapter 后的特征 g_i 更接近其标签文本嵌入 t_{y_i}：

文本特征：

t_c = CLIP_txt(prompt(c))，例如 prompt 为 “a photo of a [class name]”。

损失函数：

L_adapter = - log ( exp(cos(g_i, t_{y_i}) / τ) / Σ_{c=1}^C exp(cos(g_i, t_c) / τ) )

其中：

cos(·,·) 为余弦相似度；

τ 为温度系数（例如 0.07）；

C 为类别数。

训练过程：

(1) 冻结 CLIP 的所有参数，仅训练 Adapter 的 W_1, W_2, b_1, b_2；
(2) 在完整训练集上用上述损失训练若干 epoch（如 1–5 epoch），使图像特征与文本特征在当前数据集上更好对齐；
(3) 训练完成后固定 Adapter，后续所有静态指标与评分计算都基于 g_i，不再更新 adapter。

3.4 与后续模块的关系

顺序关系：

先训练 Adapter 并固定；

再基于 g_i 计算 SA、Div、DDS；

再训练代理分类模型并记录动态（此处用的是原始图像，不依赖 adapter）；

最后用动态构造 u_i，并用 (SA, Div, DDS) 回归 u_i 学习 w。

因此不存在“动态影响 adapter，再用动态监督静态指标”的循环依赖，逻辑清晰稳定。

对未见样本：

对新样本 x_new，先用 CLIP 提取 f_new，再经 Adapter 得到 g_new；

再基于 g_new 计算 SA_new / Div_new / DDS_new；

再用固定 ẇ 得到 Score(x_new)。

四、静态多指标样本评分模块（基于 adapter 后特征）

这一部分完全不依赖代理模型训练动态，是支撑“未见样本评分”的关键；也是后续动态权重学习的输入特征来源。

记：

训练样本 (x_i, y_i)；

CLIP 图像编码器输出 f_i，Dataset Adapter 输出 g_i（已 L2 归一化）；

CLIP 文本编码器对类别标签 y_i 的 prompt 输出 t_{y_i}。

所有静态指标均在 g_i 所在的特征空间中构建。

4.1 语义对齐度 SA（Semantic Alignment）

目的：衡量样本图像与其类别语义是否一致，抑制噪声与误标。

做法：

为每个类别 y 构造文本 prompt，例如 "a photo of a [class name]"；

使用 CLIP 文本编码器得到 t_{y_i}；

使用 CLIP 图像编码器 + Adapter 得到 g_i；

定义：

SA_i = cos(g_i, t_{y_i})

性质：

SA 高：图像与标签语义高度一致，通常是干净、典型样本；

SA 低：可能是噪声样本、误标样本或者极端异常样本。

由于 Adapter 已针对当前数据集做过对齐，SA 更能反映“在该数据集上的语义一致性”，相对原始 CLIP 特征更精确。

对未见样本：

只要有类别标签或伪标签，就可以通过 g_new 和对应 t_{y_new} 直接计算 SA_new。

4.2 多样性覆盖度 Div（基于 kNN 距离的 rank-based 稀疏度）

设计动机：

类内空间中越“稀疏”的样本，越可能提供新的变化信息和泛化收益；

我们希望构造一个对特征尺度不敏感、能跨数据集稳定对比的多样性指标；

因此采用“基于 kNN 距离的类内排序”，而非绝对距离阈值。

(1) 特征空间构建

对每个样本使用 adapter 后特征 g_i（已 L2 归一化）；

对每个类别 c，收集该类的特征集合 G_c = { g_i | y_i = c }，样本数为 N_c。

(2) 计算类内 kNN 距离 d_i

对类别 c 内每个样本 i，计算其到同类样本中第 k 个最近邻的欧氏距离：

d_i = || g_i − g_{j_k(i)} ||_2

其中 k 为全局固定参数（如 k=10），不需要 per-class 的 ε_c，也不需要其他尺度参数。

直观解释：

在类内密集区域，样本很快找到 k 个邻居 → d_i 小；

在类内稀疏区域，为找到 k 个邻居需要更远距离 → d_i 大。

(3) 将 d_i 转为相对稀疏度 rank_i

在类别 c 中，对所有 d_i 升序排序：

d_(1) ≤ d_(2) ≤ ... ≤ d_(N_c)

定义样本 i 的 rank_i 为其在排序中的位置（从 0 到 N_c − 1）；

rank_i 越大，代表样本越处于类内稀疏区域。

(4) 归一化得到 Div_i ∈ [0,1]

Div_i = rank_i / (N_c − 1)

性质：

Div_i = 0：该类中“最密集区域”的样本；

Div_i = 1：该类中“最稀疏”的样本；

由于是类内排序归一化，Div 对特征尺度不敏感，对不同数据集也更稳定。

(5) 未见样本的 Div_new

对新样本 x_new（类别 c_new）：

用 CLIP + Adapter 得到 g_new；

在 G_{c_new} 中找到 g_new 的第 k 个最近邻，得到 d_new；

将 d_new 插入训练阶段的 d_i 序列中，得到 rank_new；

定义：

Div_new ≈ rank_new / (N_{c_new} − 1)

只需一次 kNN 查询与简单排序插入操作即可，不依赖任何训练动态。

4.3 类内难度方向得分 DDS（Difficulty Direction Score）

目的：捕捉样本在类内“罕见但重要的变化方向”上的偏移，补充 SA（语义）与 Div（位置稀疏度）。

思路：

对每个类别单独在 adapter 后特征空间 G_c 上做 PCA；

类内低方差方向代表“少见但重要”的变化（例如特殊姿态、视角、光照等）；

在这些方向上偏移较大的样本，被视作具有较高“难度方向贡献”。

做法：

(1) 对每个类别 c，取 G_c 中所有特征 g_i，计算类内均值 μ_c。

(2) 对 G_c 做 PCA / 特征分解，得到主方向向量 {u_k} 及对应方差 λ_k，并按 λ_k 从小到大排序。

(3) 选择若干低方差方向，例如选择方差最小的前 K 个方向（K 可以是固定数，如 5–10，也可以基于阈值，比如累计方差小于某个比例）。

(4) 对类别为 c 的样本 i，定义：

DDS_i = Σ_{k ∈ low-variance} |⟨g_i − μ_c, u_k⟩|

性质：

DDS 高：样本在低方差方向上偏移较大，往往是“罕见但有价值的变化”，可能靠近类边界或覆盖少见模式；

DDS 低：样本在这些方向上接近类均值，更像“典型中心样本”。

整体静态特征向量：

f_i = [ SA_i, Div_i, DDS_i ]^T

将作为后续动态权重学习的输入。

五、基于训练动态学习评分权重

5.1 问题动机

SA / Div / DDS 三个静态指标“谁更重要”，不同数据集与任务差异很大；

手工设权重（如平均加权）缺乏依据，超参数搜索又很耗时；

代理模型训练动态中包含“哪些样本对训练真正有用”的信息；

但训练动态本身依赖模型与训练过程，不能直接用于未见样本评分。

因此，本项目设计为：

用代理模型训练动态构造样本效用标签 u_i（0–1 的连续值）；

再用静态特征 f_i = (SA_i, Div_i, DDS_i) 回归 u_i；

学得一个可复用的静态评分函数 Score(·)。

训练动态是“老师”，静态指标是“学生”。

5.2 代理模型与记录

代理模型：如 ResNet-18，在完整训练集上训练 E 个 epoch；

训练在原始图像空间进行，与 CLIP/Adapter 模块分离；

在训练过程中，对每个样本 x_i 记录：

(1) 每轮 loss：ℓ_t(i)
(2) 每轮是否预测正确：c_t(i) ∈ {0,1}
(3) 每轮 logits：z_t(i) ∈ ℝ^C，用于计算 margin。

5.3 EarlyLossScore：早期损失指标

目的：度量训练初期样本的“难度”。

做法：

取前 E_e 个 epoch（例如 E_e = min(10, E/3)）；

对 loss 做稳健变换以抑制极端值，例如：

ℓ̃_t(i) = log(1 + ℓ_t(i)) 或 ℓ̃_t(i) = min(ℓ_t(i), ℓ_max)

计算早期平均损失：

L_i^early = (1 / E_e) Σ_{t=1}^{E_e} ℓ̃_t(i)

在所有样本上做 min-max 归一化，得到 EarlyLossScore_i ∈ [0,1]，值越大表示早期越难学。

5.4 MarginScore：基于 margin 的边界价值指标

目的：识别在训练过程中经常处于决策边界附近的“有效边界样本”。

做法：

(1) 定义每轮 margin：

m_t(i) = z_{t,y_i}(i) − max_{c≠y_i} z_{t,c}(i)

(2) 选择一个 margin 阈值 δ>0，根据 margin 和是否预测正确定义单轮评分 s_t(i)：

若 c_t(i) = 0（分错）：s_t(i) = −1；

若 c_t(i) = 1 且 m_t(i) ≤ δ：s_t(i) = +1（正确但靠近边界）；

若 c_t(i) = 1 且 m_t(i) > δ：s_t(i) = 0（正确且远离边界）。

(3) 对所有 epoch 取平均：

\bar s_i = (1 / E) Σ_{t=1}^E s_t(i) ∈ [−1, 1]

(4) 映射到 [0,1]：

MarginScore_i = ( \bar s_i + 1 ) / 2

解释：

经常被错分 → \bar s_i 接近 −1 → MarginScore 低；

经常正确且 margin 很大 → \bar s_i 接近 0 → MarginScore 中等偏低（典型易例）；

经常正确且 margin 接近阈值 → \bar s_i 接近 1 → MarginScore 高（典型边界样本）。

5.5 ForgettingScore：基于遗忘与正确率的稳定性指标

目的：区分以下几类样本：

难学但有价值：正确率低但不乱忘；

简单典型：正确率高且不乱忘；

噪声样本：正确率低且频繁遗忘；

不稳定坏样本：正确率高但频繁遗忘。

做法：

(1) 整体正确率：

r_i = (1 / E) Σ_{t=1}^E c_t(i) ∈ [0,1]

(2) 后半程遗忘次数：

在 t > E/2 的 epoch 范围内统计从 1→0 的转变次数：

F_i = #{ t ∈ (E/2, E−1] : c_t(i)=1 且 c_{t+1}(i)=0 }

(3) 将 F_i 做 min-max 归一化，得到 \tilde F_i ∈ [0,1]。

(4) 基于 (r_i, \tilde F_i) 定义 ForgettingScore_i = g(r_i, \tilde F_i) ∈ [0,1]，例如：

r_i 低、\tilde F_i 低：难学但不乱忘 → 高分（如 0.9）；

r_i 高、\tilde F_i 低：简单典型样本 → 中等偏上（如 0.7）；

r_i 低、\tilde F_i 高：难且乱忘 → 噪声疑似 → 低分（如 0.1）；

r_i 高、\tilde F_i 高：正确率高但不断遗忘 → 不稳定 → 低分（如 0.2）。

中间区域可以用线性插值，使 g(·,·) 连续。

5.6 综合动态效用标签 u_i

三项动态指标均在 [0,1] 后，取算术平均：

u_i = ( EarlyLossScore_i + MarginScore_i + ForgettingScore_i ) / 3

u_i 可视为代理模型对样本“综合训练价值”的连续软标签。

5.7 用 Ridge 回归学习静态评分权重

现在对每个样本 i，有：

静态特征：f_i = [ SA_i, Div_i, DDS_i ]^T；

动态目标：u_i ∈ [0,1]。

采用带 L2 正则的线性回归（Ridge Regression）学习 w ∈ ℝ^3, b：

\hat u_i = w^T f_i + b

损失：

L(w,b) = (1/N) Σ_i (w^T f_i + b − u_i)^2 + λ ||w||_2^2

训练完成后：

对 w 做非负截断：w'_k = max(w_k, 0)；

再归一化：

ẇ_k = w'_k / Σ_j w'_j

得到归一化权重向量 ẇ = (ẇ_1, ẇ_2, ẇ_3)，代表 SA / Div / DDS 的相对重要性，由训练动态数据驱动确定。

六、最终评分函数与未见样本评估

6.1 最终评分定义

对任意样本 x（训练内或训练外），最终样本质量评分定义为：

Score(x) = ẇ_1 · SA(x) + ẇ_2 · Div(x) + ẇ_3 · DDS(x)

其中：

SA(x)：用 CLIP + Adapter 后特征 g(x) 与类别文本 t_y 的余弦相似度；

Div(x)：在 g(x) 所在类别的特征空间中，用 kNN 距离 rank 定义的相对稀疏度；

DDS(x)：在该类别基于 g(·) 做 PCA 得到的低方差方向上的投影幅度；

ẇ：前一阶段从训练动态学得的固定权重。

6.2 未见样本评分

对未见样本 x_new：

(1) 用 CLIP 图像编码器和 Adapter 得到 g_new；
(2) 用文本编码器得到类别嵌入 t_{y_new}，计算 SA_new；
(3) 将 g_new 插入对应类别的 G_c，计算 d_new → rank_new → Div_new；
(4) 用同类别的 μ_c 和 PCA 方向 u_k，计算 DDS_new；
(5) 用固定 ẇ 计算：

Score(x_new) = ẇ_1 SA_new + ẇ_2 Div_new + ẇ_3 DDS_new

整个过程不依赖训练动态，也不需重新训练模型。

七、基于 Score 的数据选择与 Selection Optimization

7.1 直接基于 Score 的排序选择

最直接使用方式：

对训练集中每个样本计算 Score(i)；

按 Score 排序，选取 top-k% 子集参与训练。

这实现了一个简单、直接的“样本质量驱动的数据裁剪”：高分样本保留、低分样本舍弃。

7.2 Selection Optimization：全局优化的样本选择

为缓解 group effect（个体分数高不代表组合最优），引入 Selection Optimization：将“选择哪些样本”视作一个可优化变量。

设计：

(1) 为每个样本 i 引入实值选择变量 d_i，令：

s_i = sigmoid(d_i) ∈ (0,1)

可解读为“选中程度”。

(2) 目标函数：

希望被选样本的总 Score 尽可能大；

希望被选样本比例接近目标比例 sr（如 0.5）。

定义：

L = − Σ_i s_i · Score(x_i) + β · L_ratio

其中：

L_ratio ≈ ( (1/N) Σ_i s_i − sr )^2

(可采用近似或直通估计器处理 s_i 的离散化需求。)

优化过程：

w 与静态指标已固定，Score(x_i) 固定；

针对 {d_i} 做梯度下降，更新 s_i，使目标 L 最小；

最终根据 s_i 的大小（例如阈值 0.5）来决定是否选取样本。

优势：

在给定的总比例约束下，选择的是“全局最优子集”，而不是简单 top-k；

自然考虑了样本之间的相互冗余与互补关系。

八、与直接使用训练动态评分的对比与方案意义

常见质疑：既然训练动态中已经有各种信息，为什么不直接把训练动态用作评分，而要多一层“静态指标 + 动态监督学习权重”的设计？

核心回答：

(1) 训练动态是“模型行为”，不是“样本固有属性”：

换模型、换初始化、换优化器、换 batch 顺序，动态模式都会改变；

对未见样本没有训练轨迹，无法直接给分；

仅用训练动态无法定义一个可复用的“样本质量模型”。

(2) 静态指标是“样本固有属性”：

基于 CLIP + Adapter 的语义对齐（SA）、类内相对稀疏度（Div）、类内难度方向（DDS）；

与训练过程无关，只与样本本身及其类别标签有关；

可以对任意新样本、任意新的训练过程复用。

(3) 我们的设计是：“训练动态做老师，静态评分函数做学生”：

训练动态通过 u_i 告诉我们：在这个具体任务中，哪类样本更有价值；

静态指标通过回归学习 ẇ，从而捕捉到“哪些静态特征模式对应高价值样本”；

一旦学成，静态评分函数 Score(·) 就可以在没有训练动态的情况下独立使用。

(4) Dataset Adapter 的引入进一步增强了这一框架：

Adapter 先对 CLIP 特征进行数据集适配，使 SA / Div / DDS 的统计结构更加合理；

Adapter 训练一次后固定，不与动态权重学习形成循环依赖；

对未见样本仍然可以直接前向 through adapter，然后用统一的 Score(·) 打分。

(5) 应用场景广泛而不是“很小的角落”：

自动构建和维护训练数据仓库：新增样本先打分，再决定是否加入训练集；

增强数据质量控制：对自动数据增强产生的样本、弱标或噪声数据进行质量筛选；

长期在线学习：在不断到来的数据流中有一个稳定的、与模型结构解耦的样本质量评价函数。

本项目交付的是一个“可解释、可泛化、可复用的样本质量评分函数”，而不仅仅是一套对某次训练日志的分析工具。

九、实现与实验规划简述

(1) 数据集：

CIFAR-10 / CIFAR-100 作为起点；

视时间可扩展到 Tiny-ImageNet 或 ImageNet 子集。

(2) 实现步骤：

使用预训练 CLIP 提取图像特征 f_i 与文本特征 t_y；

冻结 CLIP 主干，训练 Dataset Adapter，得到适配后特征 g_i；

基于 g_i 计算静态指标：SA_i / Div_i / DDS_i；

在原始图像上训练代理模型（ResNet-18），记录训练动态（loss / c_t / logits）；

计算 EarlyLossScore_i / MarginScore_i / ForgettingScore_i，并构造 u_i；

使用 Ridge 回归将 u_i 回归到 (SA_i, Div_i, DDS_i)，学习权重 w，得到 ẇ；

构造最终评分函数 Score(x)，对训练集与未见样本进行打分；

基于 Score 实现：

简单排序数据选择（不同选样比例）；

Selection Optimization（全局优化子集选择）；

将本方法与以下 baseline 对比：

使用全数据训练；

随机选择；

仅用单指标（如 SA 排序）；

经典方法（EL2N、MoSo 等）；

在不同噪声水平、不同数据规模、不同类别不平衡设置下评估：

分类准确率；

训练成本（epoch / 时间）；

选择子集的稳定性与可解释性；

学到的权重 ẇ 的差异及其合理性分析。

(3) 预期输出：

一套完整的样本评分与数据选择算法（含代码）；

实验结果表证明在同等选样比例下优于或不劣于已有方法；

一个可用于后续研究和工程实践的“样本质量评分函数”框架。