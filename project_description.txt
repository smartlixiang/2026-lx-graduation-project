--- 本文件用于描述本项目所有代码文件的功能、设计要点和运行细节 ---

# 1. 项目整体说明
本项目旨在实现一个面向图像分类的数据评分与数据选择框架，通过静态指标（SA/Div/DDS）评价样本质量，并用代理模型训练动态学习静态指标的权重。整体流程详见 plan.txt，但本文件重点帮助 Codex 快速定位代码功能与注意事项。

# 2. 随机种子约定（实验复现规则）
- 全项目实验种子统一由 utils/global_config.py 维护：exp_seeds = [22, 42, 96]（文件内已加注释）。
- 任何“正式实验运行脚本”（文件名不包含 test 等测试字段）必须提供 seed 超参数：
  - 传入单个正整数 → 只运行一次该 seed。
  - 传入种子列表（如 "22,42,96" 或 "[22, 42, 96]"）→ 按顺序逐个运行。
  - 默认不显式传参时读取 CONFIG.exp_seeds。
- “非正式测试脚本”（文件名带 test）默认使用 global_seed=42。
- 统一的解析/设种工具在 utils/seed.py：
  - parse_seed_list(seed) 解析字符串/列表/单个整数。
  - set_seed(seed) 同步设置 Python/NumPy/PyTorch 随机种子。

# 3. 重要目录与核心文件
以下重点描述 dataset、model、scoring、utils 目录。每个文件仅描述关键功能和易错点。

## 3.1 dataset 目录
### dataset/dataset_config.py
- 统一管理数据集名称常量（CIFAR10、CIFAR100），并提供 AVAILABLE_DATASETS 元组供 argparse choices 使用。

### dataset/dataset.py
- 数据集加载与分割的核心封装。
- 关键结构：
  - SplitConfig：保存 data_path、batch_size、num_workers、val_split、download、augment、normalize、seed、pin_memory 等参数。注意 seed 默认来自 CONFIG.global_seed，并用于随机划分训练/验证集。
  - BaseDataset：抽象类，定义 dataset_name/num_classes/_build_train_set/_build_test_set 四个接口。
  - register_dataset 装饰器：把数据集子类注册进 DATASET_REGISTRY。新增数据集时必须注册。
  - Cifar10Dataset / Cifar100Dataset：标准实现，内部依赖 utils/normalizer.NORMALIZER 生成训练/测试变换。
  - BaseDataLoader：统一入口，使用 SplitConfig + 注册表构建 DataLoader；seed 参数会传入 SplitConfig，使随机划分可复现。
- 容易忽视的细节：
  - _split_train_val 使用 torch.Generator().manual_seed(seed) 控制划分一致性。
  - DataLoader 只负责 batch/并行配置，随机种子主要控制划分而不是 shuffle（shuffle 与 torch 默认 RNG 相关）。

## 3.2 model 目录
### model/adapter.py
- AdapterMLP：两层 MLP + GELU + L2 normalize 输出，用于适配 CLIP 特征。
- CLIPFeatureExtractor：封装 openai/clip 的模型加载与特征提取。
  - __post_init__ 会自动加载模型并设置 eval。
  - encode_image/encode_text 会返回 L2-normalized 特征，避免后续指标使用不同尺度。
- resolve_adapter_dir/resolve_adapter_paths：根据 dataset + seed 解析 adapter_weights/<dataset>/<seed>/ 下的权重路径。
- load_trained_adapters：按 dataset + seed 加载图像/文本双端 Adapter，并在 meta.json 存在时校验 clip_model 一致性。
  - 默认权重文件名为 adapter_image.pt 与 adapter_context.pt。
  - hidden_dim 若未显式指定，会尝试从 meta.json 读取（默认 256）。

### model/resnet.py
- CIFAR 版本的 ResNet-18：
  - conv1 使用 3x3 stride=1，去掉 maxpool，这是 CIFAR 经典配置。
  - resnet18() 是快速工厂函数。

## 3.3 scoring 目录
### scoring/__init__.py
- 统一导出 Div / DifficultyDirection / SemanticAlignment 以及对应 Result 容器，供外部直接 import scoring.* 使用。

### scoring/Semantic_Alignment.py
- 语义对齐度 SA：图像特征与其类别文本特征的“正类相似度 - 最大负类相似度”。
- 关键函数：
  - _build_text_features：生成 prompt 并编码文本，支持文本端 adapter。
  - _margin_similarity：核心公式，注意先排除目标类别，再取最大负类相似度。
  - _quantile_normalize：按类别做分位点归一化（默认 0.2%/99.8%），避免不同类的数值尺度不一致。
- 易错点：
  - adapter 的设备与 CLIP 设备可能不一致，_encode_images 内会在 adapter_device 和 extractor.device 之间对齐。

### scoring/Diversity.py
- 多样性覆盖度 Div：类内 kNN 距离均值，反映样本在类内分布的稀疏程度。
- 关键函数：
  - _knn_mean_distance：手动分块计算全量相似度矩阵，chunk_size 决定内存占用。
  - _quantile_normalize：同样按类别归一化。
- 易错点：k 支持“正整数=邻居个数”或“0~1 小数=类内样本比例（默认 0.05 即 5%）”；实际使用时会按类别样本数解析并限制到 [1, 类内样本数-1]。

### scoring/Difficulty_Direction.py
- 类内难度方向 DDS：
  - 对类内特征做 PCA：按特征值从小到大排序后，选择“特征值和占总和处于 [eigval_lower_bound, eigval_upper_bound]”的方向集合作为难度方向，投影绝对值越大表示样本更偏离主流分布。
- 关键函数：
  - _select_difficulty_dirs：按累计特征值占比边界 [eigval_lower_bound, eigval_upper_bound] 选方向，并保证所选方向特征值和不超过上界。
  - k：不再用于 Div 式比例含义；在 DDS 中用于“最少选择方向数”的下限约束（默认 5），用于避免上界筛选后方向数过少（在不突破上界时尽量满足）。
  - _dds_from_pca：对类内特征协方差加正则后做特征分解，并使用上述规则选取难度方向。
  - _quantile_normalize：按类别做 0.2%/99.8% 分位点归一化，保证不同类可比。

## 3.4 utils 目录
### utils/global_config.py
- 集中维护项目级别默认配置（data_root、adapter_weights、pretrained_clip、global_seed 等）。
- exp_seeds = [22, 42, 96] 是实验默认随机种子列表；正式实验脚本默认从这里读取。

### utils/static_score_cache.py
- 静态指标缓存工具，统一保存/读取 SA、Div、DDS 与标签。
- 缓存路径结构改为：static_scores/<dataset>/<seed>/<重要参数目录>/，其中重要参数目录遵循 Div_5%_DDS_[2%-20%] 形式（Div 小数用百分数，Div 为整数时直接写整数）；并分文件保存 SA_cache.npz、Div_cache.npz、DDS_cache.npz。
- 缓存键包含 dataset、clip_model、图像/文本 adapter 权重哈希、Div/DDS 超参、prompt_template 和样本数，避免误读旧缓存。
- 适用于所有“静态指标计算结果不会随运行变化”的脚本，以减少重复计算成本。

### utils/normalizer.py
- Normalizer 负责数据集标准化与数据增强流水线：
  - train_tfms：可选 RandomCrop + RandomHorizontalFlip，再 ToTensor + Normalize。
  - eval_tfms：仅 ToTensor + Normalize。
- dataset_stats 用来维护不同数据集的均值方差；新增数据集需调用 register。

### utils/seed.py
- 实验复现工具：
  - parse_seed_list 可解析单个整数或列表字符串（"22,42,96" / "[22, 42, 96]"）。
  - set_seed 统一设置 Python/NumPy/PyTorch 以及 CUDA 随机种子。

# 4. 重要脚本与调用方式补充
- train_adapter.py（正式脚本，位于仓库根目录）：
  - --seed 支持单个或列表；默认 CONFIG.exp_seeds。
  - 训练图像/文本双端 Adapter，输出权重与 meta.json 到 adapter_weights/<dataset>/<seed>/。
- train_proxy.py（正式脚本）：
  - 训练 ResNet-18 代理模型并记录训练动态，日志保存到 weights/proxy_logs/[dataset]/[proxy_model_name]/[seed]/[max_epoch]/ 目录。
  - 代理训练日志体积较大，weights/proxy_logs 不会随仓库上传，需要本地生成。
- learn_scoring_weights.py（正式脚本）：
  - 基于代理日志计算 EarlyLoss/Margin/Stability，再回归学习 SA/Div/DDS 权重。
  - 权重 JSON 以 seed 作为 key（例如 "22"），元信息使用 "{seed}_meta" 保存。
  - 代理日志路径由 dataset + seed + proxy_epochs 组成，不再单独传入 cv_log_dir/npz_path。
  - 若 proxy_epochs 未设置，会在 weights/proxy_logs/<dataset>/resnet18/<seed>/ 下选取最新 epoch 目录。
  - 静态指标（SA/Div/DDS）会优先从 static_scores/<dataset>/<seed>/<重要参数目录>/ 缓存读取；读取时会解析目录参数并校验 Div/DDS 参数、样本数、adapter 哈希及索引一致性，缓存缺失或校验失败时才重算。
- scripts/diagnose_div_correlation.py（正式脚本）：
  - 用于分析静态指标与动态目标的相关性，输出分布图；多 seed 时输出到 seed 子目录。
- scripts/test_* / calculate_my_mask.py（测试脚本）：
  - 默认种子为 CONFIG.global_seed=42。
  - calculate_my_mask.py 负责计算数据选择 0/1 mask，并保存到 mask/ 路径供 train_after_selection.py 加载。
  - 计算 mask 时静态指标先查 static_scores/<dataset>/<seed>/<重要参数目录>/ 缓存；top-k 方式下缓存命中后无需重复计算。
  - 部分无用的测试脚本与历史测试结果已清理，不再随仓库保留。

# 5. CIFAR-10 数据选择实验配置（写入实验汇报用）
- 数据集：
  - 使用 CIFAR-10（训练集做子集选择；测试集评测 top-1 accuracy）。
  - 数据集存放在本项目的 data/ 目录。
- Backbone：ResNet-50，每个 cut_ratio 均从头训练（不 warm-start）。
- cut_ratio 扫描：cr ∈ {20, 30, 40, 60, 70, 80, 90, 100}（单位 %；100 表示全训练集）。
- 固定训练超参（不做网格搜索）：
  - optimizer: SGD
  - momentum: 0.9
  - weight_decay: 5e-4
  - batch_size: 128
  - init_lr: 0.1
  - epochs: 200
  - LR schedule: epoch = 60 / 120 / 160 时将 lr *= 0.2（除以 5）
- 重复次数/随机种子：
  - 每个 (cr, 方法) 跑 3 个随机种子，报告 mean/std。
  - 随机种子来自 utils/global_config.py 中的 CONFIG.exp_seeds。
  - naive 随机子集采样使用与训练相同的 seed。

## train_after_selection.py（正式脚本）
- 作用：对“数据选择后”的子集进行训练并评估，保存结果到 result/ 目录。
- 目前 random 模式为随机采样；其他方法会加载 mask/ 下对应的 0/1 mask。
- 结果保存结构：
  - result/[方法名]/[数据集名]/[模型名]/[随机种子]/result_[裁剪比例].json
  - JSON 内容包含训练元数据、最后 10 轮测试集准确率均值（key=accuracy）、以及总运行时间（秒）。
- 使用示例：
  - python train_after_selection.py --dataset cifar10 --mode random --cr 100 --seed 22,42,96 --skip_saved

## calculate_my_mask.py（测试脚本）
- 作用：计算基于 SA/Div/DDS 权重的样本评分，并按类别 top-k（k 由裁剪比例 cr 决定）生成 0/1 mask。
- method 命名约定：
  - 本方法默认使用 my_naive 或 my_learned（分别对应 weight_group=naive 与其他权重组）。
  - 如需自定义方法名，可显式传入 --method 覆盖。
- mask 保存结构：
  - mask/[方法名]/[数据集名]/[模型名]/[随机种子]/mask_[裁剪比例].npz
  - 同目录下保存 meta_info.json，记录权重组、CLIP 规格、adapter 路径、裁剪比例与统计信息等。
  - my_naive 默认使用 CONFIG.global_seed 作为 mask 路径中的随机种子。
- 静态指标缓存：
  - static_scores/<dataset>/<seed>/<重要参数目录>/ 下分别保存 SA_cache、Div_cache、DDS_cache（三者含 labels 与 indices，确保索引对齐）。
  - 适用于 top-k 数据选择；未来组合优化若改变静态指标分值，需要绕开缓存。
